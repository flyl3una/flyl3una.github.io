<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Python操作数据库]]></title>
    <url>%2F2018%2F11%2F01%2FPython%E6%93%8D%E4%BD%9C%E6%95%B0%E6%8D%AE%E5%BA%93%2F</url>
    <content type="text"><![CDATA[下列为python连接mysql,psql,oracle,sqlserver,sybase数据库方法 MySql在python3中使用pymyssql连接mysql数据库 安装依赖1pip install pymysql 使用123456789import pymysqlconn = pymysql.connect(user='user', password='123456', host='127.0.0.1', port=3306)cursor = conn.cursor()cursor.execute('select * from table') # 执行命令conn.commit() # 提交操作result = cursor.fetchall()rowcount = cursor.rowcount #影响行statuemessage = cursor.statuemssage #数据库返回消息... Postgresql安装环境1pip install psycopg2 使用1234import psycopg2conn_args = &#123;'user': 'user', 'password': 'password', 'host': '127.0.0.1', 'port': 5432, 'dbname':'dbname'&#125;conn = psycopg2.connect(**conn_args)cursor = conn.cursor() Sqlserver安装环境1pip instal pymssql 使用12345import pymssqlconnection_args = &#123;'host': '127.0.0.1', 'user': 'user', 'password': 'password'&#125;conn = pymssql.connect(**connection_args)cursor = conn.cursor()... Oracle安装依赖环境 oracle的动态链接库 到oracle官网下载instantclieng basic驱动包，并安装，然后设置环境变量指向安装目录。 如果是centos则可以到https://centos.pkgs.org/下载对应的rpm包安装。 123yum install oracle-instantclient18.3-basic-18.3.0.0.0-1.x86_64 -yecho /usr/lib/oracle/18.3/client64/lib &gt; /etc/ld.so.conf.d/oracle-instant.confldconfig python安装cx_Oracle库 1pip install cx_Oracle 使用12345678import cx_Oracledns = cx_Oracle.makedns('127.0.0.1', 1521, sid)# dns = cx_Oracle.makedns('127.0.0.1', 1521, server_name) #连接oracle数据库需要sid或server_name,server_name即为数据库名connect_args = &#123;'user': 'user', 'password': '123456', 'dsn': dsn&#125; connect_args['mode'] = cx_Oracle.SYSDBA # 如果连接用户为sysdba或者sysoper权限，则加上对应角色权限conn = cx_Oracle.connect(**connect_args)cursor = conn.cursor()... Sybase安装环境sybase需要使用odbc驱动 123yum install unixODBC -yyum install pyodbc -ypip install pyodbc 使用1234conn_string="Driver=TDS;Server=server;Port=1498;UID=user;PWD=password;TDS_VERSION=5.0"conn = pyodbc.connect(conn_string, autocommit=True)cursor = conn.cursor()...]]></content>
      <categories>
        <category>编程基础</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>数据库</tag>
        <tag>mysql</tag>
        <tag>postgresql</tag>
        <tag>oracle</tag>
        <tag>sqlserver</tag>
        <tag>sybase</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux匹配字符串操作]]></title>
    <url>%2F2018%2F11%2F01%2FLinux%E5%8C%B9%E9%85%8D%E5%AD%97%E7%AC%A6%E4%B8%B2%E6%93%8D%E4%BD%9C%2F</url>
    <content type="text"><![CDATA[linux常用的字符匹配检测工具有grep，如果需要使用正则匹配，sed和awk也很强大。 grepgrep命令用户查找文件里符合条件的字符串。 语法1grep [-abcEFGhHilLnqrsvVwxy][-A&lt;显示列数&gt;][-B&lt;显示列数&gt;][-C&lt;显示列数&gt;][-d&lt;进行动作&gt;][-e&lt;范本样式&gt;][-f&lt;范本文件&gt;][--help][范本样式][文件或目录...] 参数 样式：需要匹配的规则字符串。 参数 描述 -a/–text 不忽略二进制数据 -A [显示行数]/–after-context=&lt;显示行数&gt; 除了显示符合匹配的那一行之外，还显示后面的内容。 -b/–bytes-offset 在显示符合样式那一行之前，标识出改行第一个字符的标号。 -c/–count 计算匹配样式的列数。 -C &lt;显示行数&gt;/–context=&lt;显示行数&gt; 除了显示符合匹配样式的哪一行之外，并显示改行前后的内容。 -d &lt;动作&gt;/–directories=&lt;动作&gt; 当指定要查找的是目录而非文件时，必须使用这项参数，否则grep指令将回报信息并停止操作。 -e &lt;范本样式&gt;/–regexp=&lt;范本样式&gt; 指定字符串作为查找内容的样式。 -E/–extended-regexp 将样式为延伸的普通表示法来使用 -f&lt;规则文件&gt;/–file=&lt;规则文件&gt; 指定规则文件，其内容含有一个或多个规则样式，让grep查找符合规则的文件内容，格式为每一行一个规则样式。 -F/–fixed-regrexp 将样式视为固定字符串列表。 -G/–basic-regexp 将样式视为普通表示法来使用 -h/–no-filename 在显示符合样式哪一行前，表示改行所属文件名称 -H/–with-filename 在显示符合样式哪一行前，表示改行所属的文件名称 -i/–ignore-case 忽略字符大小写 -I/–file-with-matches 列出文件内容符合指定的样式文件名称 -L/–file-without-matchs 列出文件内容指定的样式的文件名称 -n/–line-number 在显示符合样式的哪一行前，标出改行的列数编号 -q/–quiet,–silent 不显示任何信息 -V/–version 显示版本信息 -v/–revert-match 显示不包含匹配文本的所有行 -w/–word-regexp 只显示全字符合的列 -x/–line-regexp 只显示全列符合的列 样例 123grep test *file # 查找后缀有file字样的文件中包含test字符串的文件，并打印出该字符串的行grep -r update /etc/acpi # 以磁轨方式查找符合条件的文件。并打印出该字符串所在行的内容ls ./ | grep abc #查找当前目录下文件名包含abc的文件或文件夹 awkawk是一种处理文本的工具。 12awk [选项参数] 'script' var=value file(s)awk [选项参数] -f scriptfile var=value file(s) 参数说明 参数 描述 -F fs/–field-separator fs 指定输入文件分隔符，fs是一个字符串或者一个正则表达式 -v var=value/–asign var=value 赋值一个用户定义变量 -f scriptfile/–file scriptfile 从脚本文件中读取awk命令 -mf nnn and -mr nnn 对nnn值设置内在限制，-mf选项限制分配给nnn的最大块数目；-mr选项限制记录的最大数目，这两个功能是Bell实验室awk扩展功能，标准awk不适用 -W compact/–compact/-W traditional/–traditional 在兼容模式下允许awk。 -W copyleft/–copyleft 打印简短的版权信息 -W lint-old/–line-old 打印关于不能向传统unix平台一直的警告 -W posix 打开兼容模式 -W re-interval/–re-inerval 允许间隔正则表达式的使用 -W source program-text/–source program-text 使用program-text作为源代码，可以与-f命令混用 -W version/–version 打印bug报告信息版本 基本用法123456789awk '&#123;[parttern] action&#125;' &#123;filenames&#125; #行匹配语句awk '' 只能使用单引号awk -f &#123;awk脚本&#125; &#123;文件名&#125;awk '&#123;print $1,$4&#125;' log.txt #每行按空格或TAB分隔，输出项为1、4项awk -F , '&#123;print $1,$2&#125;' log.txt #使用","分隔awk -v a=1 '&#123;print $1,$1+a&#125;' log.txt #设置变量aawk -f cal.awk log.txt #使用脚本处理log.txtls -l *.txt | awk '&#123;sum+=$6&#125; END &#123;print sum&#125;' # 计算文件大小awk 'length&gt;80' log.txt # 找出长度大于80的行seq 9 | sed 'H;g' | awk -v RS='' '&#123;for(i=1;i&lt;=NF;i++) printf("%dx%d=%d%s",i,NR,i*NR,i==NR?"\n":"\t")&#125;' #打印99乘法表 运算符 运算符 描述 = += -= *= /= %= ^= **= 赋值 ?: C条件表达式 \ \ 逻辑或 &amp;&amp; 逻辑与 ~ ~! 匹配正则表达式和不匹配正则表达式 &lt; &lt;= &gt; &gt;= != == 关系运算符 空格 连接 + - 加，减 * / % 乘，除与求余 + - ! 一元加，减和逻辑非 ^ *** 求幂 ++ – 增加或减少，作为前缀或后缀 $ 字段引用 in 数组成员 实例 123awk '$1&gt;2' log.txt # 过滤第一列大于2的行awk '$1==2 &#123;print $1, $3&#125;' log.txt #输出第一列等于2的信息awk '$1&gt;2 &amp;&amp; $2=="Are" &#123;print $1,$2,$3&#125;' log.txt # 输出第一列大于2，第二列等于Are的行信息 内建变量 变量 描述 $n 当前记录的第n个字段，字段间由FS分隔 $0 完整的输入记录 ARGC 命令行参数的数目 ARGIND 命令行中当前文件的位置(从0开始算) ARGV 包含命令行参数的数组 CONVFMT 数字转换格式(默认值为%.6g)ENVIRON环境变量关联数组 ERRNO 最后一个系统错误的描述 FIELDWIDTHS 字段宽度列表(用空格键分隔) FILENAME 当前文件名 FNR 各文件分别计数的行号 FS 字段分隔符(默认是任何空格) IGNORECASE 如果为真，则进行忽略大小写的匹配 NF 一条记录的字段的数目 NR 已经读出的记录数，就是行号，从1开始 OFMT 数字的输出格式(默认值是%.6g) OFS 输出记录分隔符（输出换行符），输出时用指定的符号代替换行符 ORS 输出记录分隔符(默认值是一个换行符) RLENGTH 由match函数所匹配的字符串的长度 RS 记录分隔符(默认是一个换行符) RSTART 由match函数所匹配的字符串的第一个位置 SUBSEP 数组下标分隔符(默认值是/034) 使用正则表达式，匹配字符串 1234awk '$2 ~ /th/ &#123;print $2,$4&#125;' log.txt # ~表示模式开始，//中是正则表达式。该行输出第二列包含th的行的第二，4列awk '/re/' log.txt # 匹配包含re的行awk 'GEGIN&#123;INORECASE=1&#125; /this/' log.txt # 忽略大小写awk '$2 !~ /th/ &#123;print $2,$4&#125;' log.txt # 模式取反 awk脚本 BEGIN{处理前执行的语句} END{处理完后执行的语句} {处理每一行时要执行的语句} sedsed命令是利用script来处理文本文件。 语法1sed [-hnv] [-e&lt;script&gt;] [-f&lt;script&gt;] [文本文件] 参数说明 参数 描述 -e/–expression= 以选项中指定的script来处理输入的文本文件。 -f&lt;script文件&gt;/–file=&lt;script文件&gt; 以选项中指定的script文件来处理输入的文本文件 -h/–help 显示帮助 -n/–quiet/–silent 仅显示script处理后的结果 -V/–version 显示版本信息 -i 直接修改原文件 动作说明 动作 描述 a 新增，a后面可以接字符串，这些字符串会在新的一行出现(目前的下一行) c 取代，c后面可以接字符串，这些字符串可以取代n1,n2之间的行 d 删除，d后面不接字符串 i 插入，i后面可以借字符串，这些字符串会出现在新的一行(目前的上一行) p 打印，将某个选择的数据打印出，p会与sed -n一起允许 s 取代，可以直接取代工作，通常和正则表达式搭配 动作需要使用两个单引号括住 实例1234567sed -e 4a\newLine testfile # 在第4行后添加一行newLinenl log.txt | sed '2,5d' #删除第2到5行nl log.txt | sed '2,5c No 2-5 number' #将2-5行内容取代为No 2-5 numbercat log.txt | sed '/root/p' # 查找文件中的root并显示cat log.txt | sed '/root/d' # 查找文件中的root并删除sed 's/要被取代的字符串/新字符串/g' # 替换字符串，支持正则sed -i 's/\.$/\!/g' log.txt #将log.txt末尾的.全部换成!]]></content>
      <categories>
        <category>折腾笔记</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python IO操作]]></title>
    <url>%2F2018%2F10%2F31%2FPython-IO%E6%93%8D%E4%BD%9C%2F</url>
    <content type="text"><![CDATA[IO在计算机中指Input/Output，即输入输出。程序运行时数据在内存中，设计到数据交换，就需要使用IO，通常是磁盘，网络，串口等需要数据交换。 操作IO的能力都是由操作系统提供的，不通的变成语言回把操作系统提供的底层库封装成对应语言的库供对应语言的使用。 文件读写读写文件是最常见的IO操作。 读文件读写文件需要使用open()方法来打开文件句柄。 1open(file, mode='r', buffering=-1, encoding=None, errors=None, newline=None, closefd=True, opener=None) file: 文件觉得路径 mode: 文件打开方式。r,r+,w,w+,a,a+；使用二进制操作文件则加上b,例如rb buffering: 指定缓冲区大小 encoding: 文件编码 newline: 设置换行符 1fp = open('/home/user/1.txt', 'r') 标志符’r’表示使用字符流形式读文件，这样就打开了一个文件，并得到了该文件的可读操作句柄fp。 如果文件不存在，open()函数回抛出IOError异常。 read()可以一次读取文件的全部内容，把所有内容读到内存中，用一个str对象表示。 readline()可以一次读取一行内容。 每个打开的文件在不使用时一定要使用close()方法关闭文件。否则回占用操作系统资源。由于操作系统打开文件数量有限，大量的文件句柄被占用会导致操作系统无法正常工作。 1fp.close() python中引入了with语句来自动帮我们调用close()方法关闭文件。 12with open('/home/user/1.txt', 'r') as fp: print(fp.read()) 如果文件不大，使用read()一次读取更方便；不能确定文件大小则可以返回调用read(size)来循环读取文件。 写文件向创建/home/user/2.txt文件并向文件写入hello world!。如果该文件原本有内容，则会被覆盖。 12with open('/home/user/2.txt', 'w') as fp: fp.write('hello world!') StringIO和BytesIOStringIO很多时候，数据读写不一定是文件，也可能会在内存中读写。 StringIO就是在内存中读写str字符串。 1234from io import StringIOwith StringIO() as fp: fp.wirte('hello world') print(fp.getvalue()) 显示结果 1hello world StringIO创建的句柄使用write()进行写操作，使用getvalue()方法进行读。 BytesIOStringIO只能操作字符串，如果要操作二进制数据，则需要使用BytesIO。 BytesIO实现了内存中读写bytes。使用方法跟StringIO相同，唯一区别就是操作str变成了bytes。 在python中，StringIO和BytesIO不建议使用清空操作，如果想要重复使用该操作，请重新创建一个新的对象。 几种方式读取文件速度 使用readlines() 123with open(file, 'r') as fp: for line in fp.readlines(): line.split('|') 该方法一次性将文件所有内容读取到内存中，速度快，耗内存。不建议打开大文件。 使用readline() 12345with open(file, 'r') as fp: line = fp.readline() while line: line.split('|') line = fp.readline() 该方法每次读取一行，占用内存极小，忽略不计。速度慢，效率低。 使用read() 123with open(file, 'r') as fp: text = fp.read() text.split('|') 一次读取所有内存到内存中，速度快，占用内存大，不建议打开大文件。 12345with open(file, 'r') as fp: text = fp.read(1024) while text: text.split('|') text = fp.read(1024) 该方法每次读取一定大小的数据，不占用内存，速度一般。 使用迭代 123with open(file) as fp: for line in fp: line.split('|') 该方法产生一个文件迭代器，自动缓冲IO和内存管理。不必担心打开大文件导致内存不够。速度快。 python里面打开文件建议使用迭代方法]]></content>
      <categories>
        <category>编程基础</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>IO</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[日期时间格式]]></title>
    <url>%2F2018%2F10%2F31%2F%E6%97%A5%E6%9C%9F%E6%97%B6%E9%97%B4%E6%A0%BC%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[在开发中，我们经常会遇到日期时间转换，所有的语言都遵循一个标准格式来进行转换。 日期格式在计算机里，标准的日期格式为： 格式 示例 dd/MM/yyyy 06/03/2007 dd-MMM-yyyy 06-Mar-2007 MM/dd/yyyy 03/06/2007 MMM dd, yyyy Mar 06, 2007 MMMMM dd, yyyy March 06, 2007 yyyy.MM.dd 2007.06.03 yyyy/MM/dd 2007/06/03 yyyy-MM-dd 2007-06-03 通常我们使用日期时间格式来描述一个具体的时间。 日期时间格式可以转换的标准日期时间格式如下： 格式 示例 dd-MM-yyyy HH’h’mm 06-03-2007 13h44 dd-MM-yyyy HH’h’MM’min’ 06-03-2007 13h44min dd-MMM-yyyy HH:mm 06-Mar-2007 13:44 dd/MM/yyyy HH’h’mm 06/03/2007 13h44 dd/MM/yyyy HH:mm 06/03/2007 13:44 dd/MM/yyyy hh:mm a zzz 06/03/2007 01:44 PM PST dd/MM/yyyy HH:mm zzz 06/03/2007 13:44 PST dd/MM/yyyy HH:mm:ss 06/03/2007 13:44:25 dd/MM/yyyy hh:mm:ss a zzz 06/03/2007 01:44:25 PM PST dd.MM.yyyy HH:mm:ss 06.03.2007 13:44:25 MM/dd/yyyy HH:mm 03/06/2007 13:44 MM/dd/yyyy hh:mm a zzz 03/06/2007 01:44 PM PST MM/dd/yyyy HH:mm zzz 03/06/2007 13:44 PST MM/dd/yyyy HH:mm:ss 03/06/2007 13:44:25 MM/dd/yyyy hh:mm:ss a zzz 03/06/2007 01:44:25 PM PST MMMMM dd, yyyy hh:mm a zzz March 06, 2007 01:44 PM PST yyyy-MM-dd HH.mm 2007-03-06 13.44 yyyy-MM-dd hh:mm a zzz 2007-03-06 01:44 PM PST yyyy.MM.dd hh:mm a zzz 2007.03.06 01:44 PM PST yyyy/MM/dd hh:mm a zzz 2007/03/06 01:44 PM PST yyyy/MM/dd HH:mm zzz 2007/03/06 13:44 PST 在上面的字符中，由两种字符类型来觉得输出的日期时间格式 复制字符：从创建格式化日期时间的格式字符串中复制。例如:/-: 解释字符：根据其对应的含义来解释出具体的时间格式。例如:y,M,d,H,m,z,Z…。所有从[A-Za-z]的字符都是解释字符，其他字符是复制字符。并非所有的解释字符都有对应的解析格式。 日期和时间的解释字符下面为日期的解释 字母序列 描述 示例 d 一个月中一位或两位数的日期 1 - 31 dd 一个月中两位数的日期 01 - 31 DDD 一年中三位数的日期 001 - 366 EEE 一周中缩写的日期 Mon - Sun EEEE 一周中日期的全称 Monday - Sunday M 一位或两位数的月份 1 - 12 MM 两位数的月份 01 - 12 MMM 三个字母的月份缩写 Jan - Dec MMMMM 月份的全称 January - December y 一位或两位数的年份 0 - 99 yy 两位数的年份 00 - 99 yyyy 四位数的年份 1999、2000、2010 下面为时间的解释 字母序列 描述 示例 a 表示 AM 或 PM AM 或 PM h 上午/下午 (1-12) 中一位或两位数的小时数 1 - 12 hh 上午/下午 (01-12) 中两位数的小时数 01 - 12 H 一天 (0-23) 中一位或两位数的小时数 0 - 23 HH 一天 (00-23) 中两位数的小时数 00 - 23 m 一小时中一位或两位数的分钟数 0 - 59 mm 一小时中两位数的分钟数 00 - 59 s 一分钟中一位或两位数的秒数 0 - 59 S 一位、两位或三位数的毫秒数 0 - 999 ss 一分钟中两位数的秒数 00 - 59 SSS 三位数的毫秒数 000 - 999 z 或 zzz 三个字母的时区缩写 EST、CST 等。 Z 相对于 GMT 的时区 -0500、-0600 等。]]></content>
      <categories>
        <category>编程基础</category>
      </categories>
      <tags>
        <tag>时间</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python时间操作]]></title>
    <url>%2F2018%2F08%2F13%2Fpython%E6%97%B6%E9%97%B4%E6%93%8D%E4%BD%9C%2F</url>
    <content type="text"><![CDATA[time模块使用unix时间，时间范围为1970~2038年。建议使用datetime来操作时间。 datetime模块获取时间123t = datetime.datetime.today() # datetime.datetime(2018, 8, 13, 19, 39, 30, 780216)# 也可以用来创建一个包含日期的时间t = datetime.datetime(2018, 8, 13, 19, 39, 30, 780216) 时间戳转换timestamp12stamp = t.timestamp() #将时间转换为timestamp数字t = datetime.datetime.fromtimestamp(stamp) #将timestamp数字转换为datetime 将字符串转换为datetime格式12cday = datetime.strptime('2018-8-1 18:19:59', '%Y-%m-%d %H:%M:%S') # 将字符串转换为指定格式now.strftime('%a, %b %d %H:%M') # 将datetime转换为指定格式 格式化类型有： 1234567891011121314%Y Year with century as a decimal number.%m Month as a decimal number [01,12].%d Day of the month as a decimal number [01,31].%H Hour (24-hour clock) as a decimal number [00,23].%M Minute as a decimal number [00,59].%S Second as a decimal number [00,61].%z Time zone offset from UTC.%a Locale's abbreviated weekday name.%A Locale's full weekday name.%b Locale's abbreviated month name.%B Locale's full month name.%c Locale's appropriate date and time representation.%I Hour (12-hour clock) as a decimal number [01,12].%p Locale's equivalent of either AM or PM. 时间计算1234t = datetime.datetime.today() # 或者datetime.datetime.now()delta = datatime.datedelta(days=5) # 参数可以是days, hours, milliseconds, microsecondsprint(t+delta)print(t-delta) 时区转换转换时区得先通过utcnow()拿到当前得UTC时间 12utc_dt = datetime.utcnow().replace(tzinfo=timezone.utc) # 拿到UTC时间，并设置时区为UTC+0:00bj_dt= utc_dt.astimezon(timezone(timedelta(hours=8))) # 设置时间为北京时间]]></content>
      <categories>
        <category>编程基础</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>datetime</tag>
        <tag>时间</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Centos7 时间管理]]></title>
    <url>%2F2018%2F08%2F09%2FCentos7-%E6%97%B6%E9%97%B4%E7%AE%A1%E7%90%86%2F</url>
    <content type="text"><![CDATA[centos7使用timedatectl来工具来管理时间，使用chrony来进行时间同步。 timedatectl查看时间在命令行里使用timedatectl可以看到 12345678 Local time: 四 2018-08-09 17:19:40 CST Universal time: 四 2018-08-09 09:19:40 UTC RTC time: 四 2018-08-09 09:19:39 Time zone: Asia/Shanghai (CST, +0800) NTP enabled: noNTP synchronized: no RTC in local TZ: no DST active: n/a Local Time其中本地时间Local time为RTC time加上时区得到的时间。如果使用date -s命令更改时间。会发现只更改了Local time而没改RTC time，重启时间将会被恢复。 NTP enabled是否打开时间同步服务，可选项为yes/no，如果为yes，则不允许更改时间。 更改时间 更新时间 1timedatectl set-time "2018-08-09 09:00:00" #可以分开单独更新时间或者日期 注意： ntp服务开启时无法更改时间 更新时区 12timedatectl set-timezone Asia/Shanghai # 只能从list-timezones时区中选择timedatectl list-timezones # 查看可以设置的时区 同步时间到硬件时间 12timedatectl set-local-rtc 1 # 或者下面的方法hwclock --systohc --localtime 设置ntp开关 1timedatectl set-ntp yes/no chrony 时间同步服务centos7使用chrony而不在使用ntpupdate 时间同步服务只能使用一个，如果使用了ntpupdate则不能使用chrony。 开启/关闭chronyd进程1systemctl start/stop chronyd 开启chronyd后可以查看时间同步服务器列表 1chronyc sources -v 配置时间服务器chronyd配置位置为/etc/chrony.conf server 添加服务器列表，可以添加多个 12server 0.centos.pool.ntp.orgserver ntp.api.bz stratumweight ​ stratumweight指令设置当chronyd从可用源中选择同步源时，每个层应该添加多少距离到同步距离。默认情况下，CentOS中设置为0，让chronyd在选择源时忽略源的层级。 driftfile ​ chronyd程序的主要行为之一，就是根据实际时间计算出计算机增减时间的比率，将它记录到一个文件中是最合理的，它会在重启后为系统时钟作出补偿，甚至可能的话，会从时钟服务器获得较好的估值。 rtcsync ​ rtcsync指令将启用一个内核模式，在该模式中，系统时间每11分钟会拷贝到实时时钟（RTC）。 allow/deny 这里你可以指定一台主机、子网，或者网络以允许或拒绝NTP连接到扮演时钟服务器的机器。 121. allow 192.168.4.52. deny 192.168/16 cmdallow/cmddeny ​ 跟上面相类似，只是你可以指定哪个IP地址或哪台主机可以通过chronyd使用控制命令 bindcmdaddress ​ 该指令允许你限制chronyd监听哪个网络接口的命令包（由chronyc执行）。该指令通过cmddeny机制提供了一个除上述限制以外可用的额外的访问控制等级。 121. bindcmdaddress 127.0.0.12. bindcmdaddress ::1 makestep​ 通常，chronyd将根据需求通过减慢或加速时钟，使得系统逐步纠正所有时间偏差。在某些特定情况下，系统时钟可能会漂移过快，导致该调整过程消耗很长的时间来纠正系统时钟。该指令强制chronyd在调整期大于某个阀值时步进调整系统时钟，但只有在因为chronyd启动时间超过指定限制（可使用负值来禁用限制），没有更多时钟更新时才生效。 使用chronyc进行交互式配置你也可以通过运行chronyc命令来修改设置，命令如下： accheck：检查NTP访问是否对特定主机可用 activity： 该命令会显示有多少NTP源在线/离线 add server：手动添加一台新的NTP服务器。 clients： 在客户端报告已访问到服务器 delete：手动移除NTP服务器或对等服务器 settime：手动设置守护进程时间 tracking：显示系统时间信息 你可以通过使用帮助命令help查看完整的命令列表]]></content>
      <categories>
        <category>折腾笔记</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>时间管理</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python3 struct解析二进制]]></title>
    <url>%2F2018%2F08%2F09%2Fpython3-struct%E8%A7%A3%E6%9E%90%E4%BA%8C%E8%BF%9B%E5%88%B6%2F</url>
    <content type="text"><![CDATA[struct模块用来处理二进制数据，例如文件二进制、socket网络数据流，C语言的结构体。 struct模块struct常用的函数有pack(), unpack(), calcsize() pack(fmt, v1, v2, …): 按照指定格式(fmt), 把数据封装成字节流(bytes) unpack(fmt, bytes): 按照指定格式(fmt), 解析字节流bytes, 返回解析后的结果tuple。 calcsize(fmt): 计算给定的格式(fmt)占用多少字节的内存。 struct支持的格式 Format C Type Python 字节数 x pad byte no value 1 c char string of length 1 1 b signed char integer 1 B unsigned char integer 1 ? _Bool bool 1 h short integer 2 H unsigned short integer 2 i int integer 4 I unsigned int integer or long 4 l long integer 4 L unsigned long long 4 q long long long 8 Q unsigned long long long 8 f float float 4 d double float 8 s char[] string 1 p char[] string 1 P void * long 4 q和Q只在机器支持64位时有作用 每个格式前可以有一共数字，表示个数 s格式表示一定长度的字符串，4s表示长度位4的字符串，但是p表示的时pascal字符串 P用来转换一共指针，其长度和机器字长相关 最后一共以用来表示指针类型的，占4个字节 为了同C种的结构体交换数据，通常以4字节对齐。struct根据本地机器字节序转换，可以用格式种的第一个字符来改变对齐方式。 Character Byte order Size and alignment @ native native 凑够4个字节 = native standard 按原字节数 &lt; little-endian standard 按原字节数 &gt; big-endian standard 按原字节数 ! network (= big-endian) standard 按原字节数]]></content>
      <categories>
        <category>编程基础</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>进制转换</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux crontab定时任务]]></title>
    <url>%2F2018%2F08%2F02%2FLinux-crontab%E5%AE%9A%E6%97%B6%E4%BB%BB%E5%8A%A1%2F</url>
    <content type="text"><![CDATA[在产品运行环境上，需要大量的定时任务对系统环境进行监控及维护处理。此时使用crontab工具能方便的完成该部分操作。 介绍crontab命令专门用于处理定时任务，crond是一个专门用于控制定时任务的守护进程。定时任务可以在固定的间隔时间执行指定的系统命令或者shell脚本及运行程序。时间间隔单位可以为分钟、小时、日、月、周及任意组合。 crontab定时任务最小周期为分钟。 crontab定时任务很适合周期性的日志分析，数据备份，数据清理工作。 使用格式1crontab [-u user] file crontab [-u user] [ -e |-l|-r] 参数 -u user: 用来设定某个用户的crontab服务； file: file定时命令文件的名字，表示file作为crontab的任务列表并载入crontab。如果在命令行中没有指定该文件，crontab命令将接收标准输入上的命令，并将他们载入crontab。 -e: 编辑某个用户的crontab文件内容。如果补指定用户，则表示编辑当前用户的crontab文件。 -l: 显示某个用户的crontab文件内容，如果补指定用户，则表示显示当前用户的crontab文件内容。 -r: 从/var/spool/cron目录中删除某个用户的crontab文件，如果不指定用户，则默认删除当前用户的crontab文件。 -i: 在删除用户的crontab文件时给出确认提示。 crontab配置文件格式配置文件地址 123/var/spool/cron/ # 该目录下存放每个用户的文件。/etc/cron.d/ # 该目录用来存放任何要执行的crontab文件或脚本。/etc/crontab # 该文件为默认的crontab配置文件 /etc/crontab文件 1234567891011121314SHELL=/bin/bash # 执行命令的shell绝对路径PATH=/sbin:/bin:/usr/sbin:/usr/bin # 设置PATH遍历MAILTO=root # 向root发送mail消息# For details see man 4 crontabs# Example of job definition:# .---------------- minute (0 - 59)# | .------------- hour (0 - 23)# | | .---------- day of month (1 - 31)# | | | .------- month (1 - 12) OR jan,feb,mar,apr ...# | | | | .---- day of week (0 - 6) (Sunday=0 or 7) OR sun,mon,tue,wed,thu,fri,sat# | | | | |# * * * * * user-name command to be executed 分 时 日 月 周 执行用户 要运行的命令 第一列为分钟0~59 第二列为小时0~23 第三列为日期1~31 第四列为月份1~12 第五列为星期几0~7 第六列为运行命令的用户 第7列为要运行的命令 常用方法实例1：每1分钟执行一次myCommand1* * * * * user myCommand 实例2：每小时的第3和第15分钟执行13,15 * * * * user myCommand 实例3：在上午8点到11点的第3和第15分钟执行13,15 8-11 * * * user myCommand 实例4：每隔两天的上午8点到11点的第3和第15分钟执行13,15 8-11 */2 * * user myCommand 实例5：每周一上午8点到11点的第3和第15分钟执行13,15 8-11 * * 1 user myCommand 实例6：每晚的21:30重启smb130 21 * * * user systemctl restart smb 实例7：每月1、10、22日的4 : 45重启smb145 4 1,10,22 * * user systemctl restart smb 实例8：每周六、周日的1 : 10重启smb110 1 * * 6,0 user systemctl restart smb 实例9：每天18 : 00至23 : 00之间每隔30分钟重启smb10,30 18-23 * * * user systemctl restart smb 实例10：每星期六的晚上11 : 00 pm重启smb10 23 * * 6 user systemctl restart smb 实例11：每一小时重启smb1* */1 * * * user systemctl restart smb 实例12：晚上11点到早上7点之间，每隔一小时重启smb10 23-7 * * * user systemctl restart smb 启动方法12345sudo systemctl start crond #启动服务sudo systemctl stop crond #关闭服务sudo systemctl restart crond #重启服务sudo systemctl reload crond #重新载入配置sudo systemctl status crond #查看服务状态 参考文献http://linuxtools-rst.readthedocs.io/zh_CN/latest/tool/crontab.html]]></content>
      <categories>
        <category>折腾笔记</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>crontab</tag>
        <tag>crond</tag>
        <tag>定时任务</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python Pandas使用]]></title>
    <url>%2F2018%2F07%2F14%2FPython-pandas%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[Pandas介绍 pandas包含高级的数据结构和精巧的工具，使得Python处理数据非常快速和简单。pandas建立在NumPy之上，使得以NumPy为中心的应用很容易使用。 Pandas安装1pip install pandas 建议使用anaconda，自带pandas Pandas数据结构入门pandas有两个重要的数据结构：Series和DataFrame。这两个数据结构易用于大多数应用程序基础。 Seriesseries使一个一维的类似数组的对象，包含一个数组的数据（任何NumPy的数据类型）和一个与数据关联的数组标签，叫做索引。 Series创建方法1class Series(data=None, index=None, dtype=None, name=None, copy=False, fastpath=False) data: Series的数据源 index: Series的索引 dtype: 数据类型 name: 指定Series的名称，可以用Series.name访问。在DataFrame中，每一列的列明在该列单独取出来时就成了Series的名称 最简单的Series由一个数组的数据构成 123456789101112&gt;&gt;&gt; from pandas import Series&gt;&gt;&gt; obj = Series([4, 65, -4, 3])&gt;&gt;&gt; obj0 41 652 -43 3dtype: int64&gt;&gt;&gt; obj.valuesarray([ 4, 65, -4, 3])&gt;&gt;&gt; obj.indexRangeIndex(start=0, stop=4, step=1) 可以看到索引是一个RangeIndex对象，值是一个array数组。 通常我们会创建一个带有索引来确定每个数据点的Series 123456789101112&gt;&gt;&gt; obj2 = Series([4, 15, -3, 0, 5], index=['a', 'b', 'c', 'd', 'e'])&gt;&gt;&gt; obj2.indexIndex(['a', 'b', 'c', 'd', 'e'], dtype='object')&gt;&gt;&gt; obj2.valuesarray([ 4, 15, -3, 0, 5])&gt;&gt;&gt; obj2a 4b 15c -3d 0e 5dtype: int64 Series还可以通过dict来创建 123456&gt;&gt;&gt; a = &#123;'a': 'a', 'b': 'b', 'c': 'c'&#125;&gt;&gt;&gt; Series(a)a ab bc cdtype: object Series使用与Numpy数组相比，Seires可以使用索引里的值来选择一个单一值或一个值集。 1234567&gt;&gt;&gt; obj2['a']4&gt;&gt;&gt; obj2[['a', 'b', 'c']]a 4b 15c -3dtype: int64 Numpy数组操作，对Series进行计算后，依旧会保持索引和值间的关联。 例如对Series进行布尔数组过滤，纯量计算，使用数学函数 123456789101112131415161718&gt;&gt;&gt; obj2[obj2 &gt; 0]a 4b 15e 5dtype: int64&gt;&gt;&gt; obj2 ** 2a 16b 225c 9d 0e 25&gt;&gt;&gt; np.exp(obj2)a 5.459815e+01b 3.269017e+06c 4.978707e-02d 1.000000e+00e 1.484132e+02dtype: float64 Series中索引对应的值如果不存在，就会出现一个NAN值，表示为空，这在pandas中被用来标记数据缺失或NA 值。pandas中使用函数isnull和notnull来检查数据丢失。 123456789101112131415161718192021222324&gt;&gt;&gt; values = &#123;1: 1, 2: 2, 3: 3, 4: 4&#125;&gt;&gt;&gt; indexs = [1, 2, 3, 4, 5]&gt;&gt;&gt; obj5 = Series(values, index=indexs)&gt;&gt;&gt; obj51 1.02 2.03 3.04 4.05 NaNdtype: float64&gt;&gt;&gt; obj5.isnull()1 False2 False3 False4 False5 Truedtype: bool&gt;&gt;&gt; obj5.notnull()1 True2 True3 True4 True5 Falsedtype: bool Series的索引可以直接通过Series.index进行改变 12345678910111213&gt;&gt;&gt; obj0 41 652 -43 3dtype: int64&gt;&gt;&gt; obj.index=['hah', 'heihei', 'hello', 'world']&gt;&gt;&gt; objhah 4heihei 65hello -4world 3dtype: int64 Series对象本身和它的索引都有一个name属性，它和pandas的其他一些关键功能整合在一起。 12345678910&gt;&gt;&gt; obj2.name='obj2'&gt;&gt;&gt; obj2.index.name='index'&gt;&gt;&gt; obj2indexa 4b 15c -3d 0e 5Name: obj2, dtype: int64 DataFrame一个DataFrame表示一个表格，类似电子表格的数据结构，包含一个经过排序的列表集，他们每一个都可以有不同的类型值(数字，字符串，布尔等)。DataFrame有行和列的索引；它可以被看做一个Series的字典，与其他（如R语言的data.frame）类似的DataFrame结构相比，在DataFrame里的面相行和面向列的操作大致是对称的。在底层，数据是作为一个或多个二位数组存储的，而不是列表、字典、或其他一维的数组集合。 DataFrame在内部吧数据存储为一个二维数组格式，因此可以采用分层索引以表格格式来表示高纬度的数据。分层索引是pandas中许多先进的数据处理功能的关键因素。 DataFrame创建DataFrame定义 1class DataFrame(data=None, index=None, columns=None, dtype=None, copy=False) data: 数据源 Index: 索引 columns：列 DataFrame与Series一样，如果不设置索引，索引会自动分配，并且对列进行了排序。 创建一个简单的DataFrame，常用的方法是用一个相同长度的列表的字典或Numpy数组进行创建。 1234567891011&gt;&gt;&gt; data = &#123;'a': ['abc', 'bcd', 'cde'],... 'b': ['bbb', 'ccc', 'ddd'],... 'c': ['cba', 'dcb', 'edc']&#125;&gt;&gt;&gt; data&#123;'a': ['abc', 'bcd', 'cde'], 'b': ['bbb', 'ccc', 'ddd'], 'c': ['cba', 'dcb', 'edc']&#125;&gt;&gt;&gt; frame = DataFrame(data)&gt;&gt;&gt; frame a b c0 abc bbb cba1 bcd ccc dcb2 cde ddd edc DataFrame与Series一样，如果传递了一个行，但不包括在data中，结果中会表示为NA值 123456&gt;&gt;&gt; frame1 = DataFrame(data, columns=['a', 'b', 'c', 'd'], index=[111, 222, 333])&gt;&gt;&gt; frame1 a b c d111 abc bbb cba NaN222 bcd ccc dcb NaN333 cde ddd edc NaN DataFrame与Series使用方式相同，可以通过字典激发或属性来检索。 12345678910111213&gt;&gt;&gt; frame1.indexInt64Index([111, 222, 333], dtype='int64')&gt;&gt;&gt; frame1.valuesarray([['abc', 'bbb', 'cba', nan], ['bcd', 'ccc', 'dcb', nan], ['cde', 'ddd', 'edc', nan]], dtype=object)&gt;&gt;&gt; frame1.columnsIndex(['a', 'b', 'c', 'd'], dtype='object')&gt;&gt;&gt; frame1['a']111 abc222 bcd333 cdeName: a, dtype: object 如果通过嵌套字典格式传递到DataFrame，则外部建值会解释为列的索引，内部键会解释为行的索引 123456789101112131415161718&gt;&gt;&gt; data1 = &#123;'a': &#123;1: '11', 2: '22'&#125;, 'b': &#123;11: '111', 22: '222'&#125;, 'c': &#123;'111': '1111', 222: '2222'&#125;&#125;&gt;&gt;&gt; data2 = &#123;'a': &#123;1: '11', 2: '22'&#125;, 'b': &#123;11: '111', 22: '222'&#125;, 'c': &#123;'111': '1111', 222: &#123;'haha': 'haha'&#125;&#125;&#125;&gt;&gt;&gt; DataFrame(data1) a b c1 11 NaN NaN2 22 NaN NaN11 NaN 111 NaN22 NaN 222 NaN111 NaN NaN 1111222 NaN NaN 2222&gt;&gt;&gt; DataFrame(data2) a b c1 11 NaN NaN2 22 NaN NaN11 NaN 111 NaN22 NaN 222 NaN111 NaN NaN 1111222 NaN NaN &#123;'haha': 'haha'&#125; Series也可以以相同方式来处理。 如果一个DataFrame的index和columns有name，也会被显示出来。 跟Series一样，values属性返回一个保护在DataFrame中的数组的二维ndarray。 123456789101112&gt;&gt;&gt; frame2 = DataFrame(data1)&gt;&gt;&gt; frame2.index.name = 'frame_index_name'&gt;&gt;&gt; frame2.columns.name = 'columns_name'&gt;&gt;&gt; frame2columns_name a b cframe_index_name1 11 NaN NaN2 22 NaN NaN11 NaN 111 NaN22 NaN 222 NaN111 NaN NaN 1111222 NaN NaN 2222 二维ndarray 一个数据矩阵，有可选的行标和列标 数组，列表或元组的字典 每一个序列成为DataFrame中的一列。所有的序列必须有相同的长度。 NumPy的结构/记录数组 和“数组字典”一样处理 Series的字典 每一个值成为一列。如果没有明显的传递索引，将结合每一个Series的索引来形成结果的行索引。 字典的字典 每一个内部的字典成为一列。和“Series的字典”一样，结合键值来形成行索引。 字典或Series的列表 每一项成为DataFrame中的一列。结合字典键或Series索引形成DataFrame的列标。 列表或元组的列表 和“二维ndarray”一样处理 另一个DataFrame DataFrame的索引将被使用，除非传递另外一个 NumPy伪装数组（MaskedArray） 除了蒙蔽值在DataFrame中成为NA/丢失数据之外，其它的和“二维ndarray”一样 DataFrame使用 索引DataFrame是返回的列是一个底层数据的视窗，而不是一个拷贝。因此，任何在Series上对数据的修改都会直接影响DataFrame，列可以使用Series的copy函数来显示的拷贝。 1234567891011121314151617181920212223242526272829abc = frame['a']&gt;&gt;&gt; frame1 a b c d111 abc bbb cba NaN222 bcd ccc dcb NaN333 cde ddd edc NaN&gt;&gt;&gt; abc.values[1] = 'fff'&gt;&gt;&gt; frame1 a b c d111 abc bbb cba NaN222 fff ccc dcb NaN333 cde ddd edc NaN&gt;&gt;&gt; bbb = frame['a'].copy()&gt;&gt;&gt; bbb0 abc1 bcd2 cdeName: a, dtype: object&gt;&gt;&gt; bbb.values[1] = 'haha'&gt;&gt;&gt; frame1 a b c d111 abc bbb cba NaN222 fff ccc dcb NaN333 cde ddd edc NaN&gt;&gt;&gt; bbb0 abc1 haha2 cdeName: a, dtype: object 索引对象 索引对象是不可变的 索引对象是不可变的 Index 最通用的索引对象，使用Python对象的NumPy数组来表示坐标轴标签。 Int64Index 对整形值的特化索引。 MultiIndex “分层”索引对象，表示单个轴的多层次的索引。可以被认为是类似的元组的数组。 DatetimeIndex 存储纳秒时间戳（使用NumPy的datetime64 dtyppe来表示）。 PeriodIndex 对周期数据（时间间隔的）的特化索引。 每个索引都有许多关于集合逻辑的方法和属性，且能够解决它所包含的数据的常见问题。 append 链接额外的索引对象，产生一个新的索引 diff 计算索引的差集 intersection 计算交集 union 计算并集 isin 计算出一个布尔数组表示每一个值是否包含在所传递的集合里 delete 计算删除位置i的元素的索引 drop 计算删除所传递的值后的索引 insert 计算在位置i插入元素后的索引 is_monotonic 返回True，如果每一个元素都比它前面的元素大或相等 is_unique 返回True，如果索引没有重复的值 unique 计算索引的唯一值数组 使用pandas进行数据分析使用reindex来重建索引pandas对象的一个关键方法是reindex，该方法可以使数据符合一个新的索引来构造新的对象。 在Series上使用reindex重排数据，使他符合新的索引，如果索引值不存在则引入缺失数据值。 123456789101112131415&gt;&gt;&gt; obj10 = Series([4.5, 7.2, -5.3, 3.6], index=['d', 'b', 'a', 'c'])&gt;&gt;&gt; obj10d 4.5b 7.2a -5.3c 3.6dtype: float64&gt;&gt;&gt; obj11 = obj10.reindex(['a', 'b', 'c', 'd', 'e'])&gt;&gt;&gt; obj11a -5.3b 7.2c 3.6d 4.5e NaNdtype: float64 method选项可以让重建索引时对值进行内插或填充，例如使用ffill方法前向填充值。 123456789&gt;&gt;&gt; obj13 = Series(['blue', 'purple', 'yellow'], index=[0, 2, 4])&gt;&gt;&gt; obj13.reindex(range(6), method='ffill')0 blue1 blue2 purple3 purple4 yellow5 yellowdtype: object reindex的method提供的方法有 参数 描述 ffill或pad 前向（或进位）填充 bfill或backfill 后向（或退位）填充 对于DataFrame，reindex可以改变（行）索引、列或两则。当只传入一个序列时，结果中的行被重新索引了。 12345678910111213141516171819&gt;&gt;&gt; frame4 = DataFrame(np.arange(9).reshape((3, 3)), index=['a', 'c', 'd'], columns=['Ohio', 'Texas', 'California'])&gt;&gt;&gt; frame4 Ohio Texas Californiaa 0 1 2c 3 4 5d 6 7 8&gt;&gt;&gt; frame5 = frame4.reindex(['a', 'b', 'c', 'd'])&gt;&gt;&gt; frame5 Ohio Texas Californiaa 0.0 1.0 2.0b NaN NaN NaNc 3.0 4.0 5.0d 6.0 7.0 8.0&gt;&gt;&gt; frame6 = frame4.reindex(columns=['Texas', 'Utah', 'California'])&gt;&gt;&gt; frame6 Texas Utah Californiaa 1 NaN 2c 4 NaN 5d 7 NaN 8 使用带标签索引的ix可以把重新索引做的更简单 1234567891011&gt;&gt;&gt; framecolumns_name a b c0 abc bbb cba1 bcd ccc dcb2 cde ddd edc&gt;&gt;&gt; frame.ix[[-1, 0, 1, 2,], ['a', 'c', 'b']]columns_name a c b-1 NaN NaN NaN 0 abc cba bbb 1 bcd dcb ccc 2 cde edc ddd reindex函数的参数 index 作为索引的新序列。可以是索引实例或任何类似序列的Python数据结构。一个索引被完全使用，没有任何拷贝。 method 插值（填充）方法，见表格5-4的选项 fill_value 代替重新索引时引入的缺失数据值 limit 当前向或后向填充时，最大的填充间隙 level 在多层索引上匹配简单索引，否则选择一个子集 copy 如果新索引与就的相等则底层数据不会拷贝。默认为True(即始终拷贝） 从一个坐标轴删除项目如果有一个索引数组或列表且没用这些条目，drop方法将返回一个新的对象并从坐标轴中删除指定的一个或多个值 1234&gt;&gt;&gt; frame.drop(0)columns_name a b c1 bcd ccc dcb2 cde ddd edc 索引，过滤使用标签切片和正常的python切片不一样，它会吧结束点也包括在内。 12345&gt;&gt;&gt; obj['hah': 'hello']hah 4heihei 65hello -4dtype: int64 索引DataFrame来检索一个或多个列 12345&gt;&gt;&gt; frame[['a', 'b']]columns_name a b0 abc bbb1 bcd ccc2 cde ddd 下面有用父标签索引的都引入到了ix obj[val] 从DataFrame选择单一列或连续列。特殊情况下的便利：布尔数组（过滤行），切片（行切片），或布尔DataFrame（根据一些标准来设置值）。 obj.ix[val] 从DataFrame的行集选择单行 obj.ix[:, val] 从列集选择单列 obj.ix[val1, val2] 选择行和列 reindex 方法 转换一个或多个轴到新的索引 xs 方法 通过标签选择单行或单列到一个Series icol, irow 方法 通过整数位置，分别的选择单行或单列到一个Series get_value, set_value 方法 通过行和列标选择一个单值 参考http://pda.readthedocs.io/en/latest/chp5.html]]></content>
      <categories>
        <category>科学计算</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>科学计算</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python日志模块logging]]></title>
    <url>%2F2018%2F06%2F27%2FPython%E6%97%A5%E5%BF%97%E6%A8%A1%E5%9D%97logging%2F</url>
    <content type="text"><![CDATA[在项目开发及维护中，日志是特别重要的。 python自带的logging库可以很好的完成日志功能。 简单的日志功能logging模块提供了5种日志级别。 级别 值 描述 CRITICAL(中断) logging.CRITICAL(50) 严重错误，表明程序已经不能继续运行了。 ERROR(错误) logging.ERROR(40) 严重的问题，程序已经不能执行一些功能了 WARNING(警告) logging.WARNING(30) 程序可能会发生某些问题 INFO(信息) logging.INFO(20) 普通信息，用来证明程序按预期工作 DEBUG(调试) logging.DEBUG(10) 详细信息，只允许调试时查看的信息 直接使用logging.info(), logging.waring(), logging.error()等方法默认将日志信息打印到屏幕上(stdout) 12import logginglogging.info('this is a log.') 然而写日志目的就是将程序运行信息，错误信息等需要用来排错的信息输出到文件。 123456import logginglogging.basicConfig(filename='example.log', level=logging.DEBUG, filemode='w')# filemode = 'w' 每次运行，重写loglogging.debug('this is debug data.')logging.info('this is info data.')logging.warning('this is warn data.') 查看文件内容 123DEBUG:root:this is debug data.INFO:root:this is info data.WARNING:root:this is warn data. 日志只会将日志内容级别大于等于日志文件级别的数据输出到日志文件中。 如果把level调到INFO，则日志文件中不会显示DEBUG那一行数据。 详细的Log日志上述的日志输出太简单了。如果程序日志都是上述格式，大量日志将无法利用，无法定位错误。 日志的控制通过下面几个类实例来实现 Logger记录器：暴露了程序代码能直接使用的接口。 Handler处理器：将记录器产生的日志记录发送到对应目的地。 Filter过滤器，提供了更好的粒度控制，它可以决定输出哪些日志记录。 Formatter格式化器，指明了最终输出中日志内容的格式。 Logger记录器创建Logger 1logger = logging.getLogger(logger_name) 注意：Logger时一个树形级结构。一个Logger可以包含一个或多个Handler和Filter，即Logger与Handler或Filter是一对多的关系 建议：logger_name使用全局变量__name__，可以避免名字冲突，还能很清楚的分辨是哪个日志。 创建Logger实例后，可以给日志设置级别，添加处理器handler。 logger.setLevel(logging.INFO): 设置级日志别，低于该级别的日志不会被输出 logger.addHandler(handler_name): 为Logger实例添加一个处理器 logger.removeHandler(handler_name): 为Logger实例删除一个处理器 Handler处理器handler处理器有很多种，常用的的有：StreamHandler, FilterHandler, NullHandler,（RotatingFileHandler, TimeRotatingFileHandler）。RotatingFileHandler和TimeRotatingFileHandler会自动回滚日志文件。 Handler有下列方法 handler.setLevel(): 指定日志级别 handler.setFormatter(): 设置一个格式化器 handler.addFilter(): 添加一个过滤器，可以增加多个 handler.removeFilter(): 删除一个过滤器 StreamHandler 创建方法 1handler = logging.StreamHandler(stream=None) FileHandler创建方法 1handler = logging.FileHandler(filename, mode='a', encoding=None, delay=False) RotatingFileHandler创建方法 1handler = logging.handlers.RotatingFileHandler(filename, maxBytes=0, backupCount=0, encoding=None, delay=False) maxBytes：大于0时，表示日志文件接近maxBytes大小时会回滚日志文件。 backupCount：最大存留的日志文件数，超出该文件数后，会自动删除最旧的日志文件。旧日志文件名为filename.log.(num) TimeRotatingFileHandler创建方法 1handler = logging.handlers.RotatingFileHandler(filename, when='h', interval=1, backupCount=0, encoding=None, delay=False, utc=False, atTime=None) when: 表示根据时间回滚的时间周期，有s(econd), m(inute), h(our), d(ay), w(eek)。 interval: 表示周期的数量，默认1为1个周期。 backupCount: 最大存留日志文件数。旧日志文件名为filename.log.(TIME) 日志回滚：默认日志为filename.log，回滚时会将该文件重命名为filename.log.xxx，再新建一个filename.log，并将日志句柄转移到新日志文件上。 建议在实际应用中使用TimeRotatingFileHandler方法，使用时间回滚日志，能更加快速定位日志信息。 Formatter格式化器使用Formatter对象设置日志信息最后的规则、结构和内容，默认的时间格式为%Y-%m-%d %H:%M:%S。 创建方法 1formatter = logging.Formatter(fmt=None, default=None) fmt为日志消息的格式化字符串，datefmt时日期字符串，如果不值命fmt，将使用%(message)s。如果不值命datefmt，将使用ISO8601日期格式。 有用的format格式 格式 描述 %(levelno)s 打印日志级别的数值 %(levelname)s 打印日志级别名称 %(pathname)s 打印当前执行程序的路径 %(filename)s 打印当前执行程序名称 %(funcName)s 打印日志的当前函数 %(lineno)d 打印日志的当前行号 %(asctime)s 打印日志的时间 %(thread)d 打印线程id %(threadName)s 打印线程名称 %(process)d 打印进程ID %(message)s 打印日志信息 Filter过滤器Handlers和Loggers可以使用Filters来完成比级别更复杂的过滤。Filter基类只允许特定Logger层次以下的事件。 创建方法 1filter = logging.Filter(name='') 日志配置 显示创建记录器Logger、处理器Handler和格式化器Formatter，并进行配置 通过简单方式进行配置，使用basicConfig()函数直接进行配置 通过配置文件进行配置，使用fileConfig()函数读取配置文件 通过配置字典进行配置，使用dictConfig() 函数读取配置信息 通过网络进行配置，使用listen()函数进行网络配置 basicConfig关键字参数 关键字 描述 filename 创建一个FileHandler，使用指定的文件名，而不是使用StreamHandler。 filemode 如果指明了文件名，指明打开文件的模式（如果没有指明filemode，默认为’a’）。 format handler使用指明的格式化字符串。 datefmt 使用指明的日期／时间格式。 level 指明根logger的级别。 stream 使用指明的流来初始化StreamHandler。该参数与’filename’不兼容，如果两个都有，’stream’被忽略。 实例一个简单的写文件日志实例 12345678910111213141516171819202122232425262728# -*- encoding:utf-8 -*-import logging# create loggerlogger_name = "example"logger = logging.getLogger(logger_name)logger.setLevel(logging.DEBUG)# create file handlerlog_path = "./log.log"fh = logging.FileHandler(log_path, when='d')fh.setLevel(logging.WARN)# create formatterfmt = "%(asctime)-15s %(levelname)s %(filename)s %(lineno)d %(process)d %(message)"datefmt = "%a %d %b %Y %H:%M:%S"formatter = logging.Formatter(fmt, datefmt)# add handler and formatter to loggerfh.setFormatter(formatter)logger.addHandler(fh)# print log infologger.debug('debug message')logger.info('info message')logger.warn('warn message')logger.error('error message')logger.critical('critical message') 下面为创建一个日志工厂类，可以生成一个基于StreamHandler输出到屏幕或者创建TimeRotatingFileHandler输出到文件的日志对象。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182#!/usr/bin/env python3.6import loggingimport logging.handlersimport osimport sysimport tracebackimport timesetting = &#123; 'RUN_ENV': 'debug', 'ROOT_LOG_DIR': '/var/log/'&#125;def get_current_user(): """ 获取当前用户 :return: 当前用户 or '' """ status, stdout = subprocess.getstatusoutput('id -un') if status: return '' else: return stdout.strip()class LogFactory(object): def __init__(self, log_name, project='', log_level=None, handler_type='file', date_file=True, rotate='H', backupCount=30, task_id=''): """ 使用LogFactory生成一个日志对象 :param log_name: 日志模块名称,日志位于setting['ROOT_LOG_DIR']/log_name/user文件中 :param log_level: 日志级别，只允许logging.INFO,logging.DEBUG, logging.WARN, logging.ERROR, logging.CRITICAL :param project: 项目名称，若handler_type为file，则日志目录为log_segging.ROOT_LOG_DIR / project / . :param handler_type: 日志流类型，允许file或者console,默认为file :param rotate: 日志回滚周期，s/S(econds),m/M(inute),h/H(our),d/D(ay),w/W(eek)，默认为小时, :param backupCount: 日志备份日期，默认30小时 """ self.log_level = log_level self.log_name = log_name.split('.')[0] self.handler_type = handler_type self.date_file = date_file self.project = project self.rotate = rotate self.backupCount = backupCount self.task_id = '_' + str(task_id) if task_id else '' self.logger = self.get_logger() try: if not self.logger: error_info = [ 'self.log_name:' + str(self.log_name), 'self.log_level:' + str(self.log_level), 'self.handler_type:' + str(self.handler_type), 'self.projcect:' + str(self.project), 'self.date_file:' + str(self.date_file) ] raise Exception("get logger error.\tself info:\n"+'\n'.join(error_info)) except: raise SystemExit(1) else: self.import_log_funcs() def get_logger(self): """ 获取日志对象 :return: logger对象：成功 0：level或者type错误 """ #判断运行环境 if not self.log_level: if setting['RUN_ENV'] == 'debug': self.log_level = logging.DEBUG else: self.log_level = logging.INFO # 分为不同类型的handler生成不同的日志对象 if self.handler_type == 'file': return self.get_file_logger() elif self.handler_type == 'console': return self.get_console_logger() def get_file_logger(self): """ 获取一个文件类型日志对象 :return: logger对象：成功 0：level或者type错误 """ try: # 如果self.project存在，则该日志目录位于log_root/project下 if self.project is '': log_root = setting['ROOT_LOG_DIR'] else: log_root = os.path.join(setting['ROOT_LOG_DIR'], self.project.lstrip('/')) # 如果日志目录不存在，则创建目录。 if not os.path.exists(log_root): os.mkdir(log_root) # 使用用户名加日期为目录或文件名。 current_user = get_current_user() log_path = os.path.join(log_root, self.log_name, current_user + self.task_id + '.log') logger = logging.getLogger('.'.join([self.log_name, current_user])) # 创建一个以日志文件大小回滚的日志对象 # fh = logging.handlers.RotatingFileHandler(log_path) # 创建一个以时间回滚的日志对象 fh = logging.handlers.TimedRotatingFileHandler(log_path, when=self.rotate, backupCount=self.backupCount) # fh.suffix += '.log' fh.setLevel(self.log_level) fh.setFormatter(self.get_formatter()) logger.setLevel(self.log_level) logger.addHandler(fh) except Exception: print('log_path:', log_path) traceback.print_exc() return 0 return logger def get_console_logger(self): """ 获取一个stderr流类型日志对象 :return: logger对象：成功 0：level或者type错误 """ try: logger = logging.getLogger(self.log_name) ch = logging.StreamHandler(stream=sys.stdout) ch.setLevel(self.log_level) ch.setFormatter(self.get_formatter()) logger.setLevel(self.log_level) logger.addHandler(ch) except: traceback.print_exc() return 0 return logger def get_formatter(self): """ 获取一个日志输出格式 :return: logging库的Formatter匹配对象formatter """ # return logging.Formatter('%(asctime)s &lt;%(filename)s line:%(lineno)d&gt; %(levelname)s - %(message)s') return logging.Formatter('[%(asctime)s &lt;%(pathname)s-%(funcName)s:%(lineno)d&gt;](%(levelname)s):%(message)s') def import_log_funcs(self): """ 将logging的输出日志函数导出到该类 :return: 0 """ if not self.logger: raise Exception('not have logger.') log_funcs = ['info', 'warning', 'error', 'critical', 'exception'] if setting['RUN_ENV'] == 'debug': log_funcs.append('debug') for func_name in log_funcs: func = getattr(self.logger, func_name) setattr(self, func_name, func) def trace(self, number=10): """ 将栈错误信息输入日志，level为error。默认栈为3层 :param number: 想要打印的栈信息层数 :return: 0 """ if setting['RUN_ENV'] != 'debug': return info = sys.exc_info() if number &gt;= len(info): number = len(info)-1 for file, line, func, text in traceback.extract_tb(info[number]): self.error('%s line:%s in %s:%s' % (file, line, func, text)) self.error('%s: %s' % info[:number])def test(mlogger): mlogger.info('xxx') mlogger.debug('abc') mlogger.warning('asc') mlogger.error('dssa') mlogger.critical('crit')if __name__ == '__main__': test_log = LogFactory('test', handler_type='file', project='test', rotate='h', backupCount=24*30) test(test_log) 参考文献官方文档 Formatter配置]]></content>
      <categories>
        <category>编程基础</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>日志</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python单元测试]]></title>
    <url>%2F2018%2F06%2F24%2Fpython%E5%8D%95%E5%85%83%E6%B5%8B%E8%AF%95%2F</url>
    <content type="text"><![CDATA[在一个项目中，单元测试可以很有效的排除bug。 单元测试可以对单个模块、函数、类进行正确性检验测试。 如果对某个功能进行了修改，只需要使用单元测试再跑一次，通过就可以说明修改正确，没有影响到原有的功能行为。 unittest模块python自带了unittest模块，用来进行单元测试功能。 编写单元测试时，需要编写一个测试类，从unittest.TestCase类继承， 以test开头的方法就是测试方法，不以test开头的方法不被认为是测试方法，测试的时候不会执行。 对每一个类测试都需要编写一个test_xxx()方法。由于unittest.TestCase提供了很多内置的条件判断，只需要调用这些方法就可以断言输出是否是我们所期望的。最常用的断言就是assertEqual()： 1self.assertEqual(abs(-1), 1) #断言判断函数返回的结果是否等于1 另一个重要的断言是期待抛出指定类型的Error，比如通过d[&#39;empty&#39;]访问不存在的key时，断言是否会抛出KeyError： 12with self.assertRaises(KeyError): value = d['empty'] 而通过d.empty访问不存在的key时，我们期待抛出AttributeError： 12with self.assertRaise(AttributeError): value = d.empty 运行单元测试写完单元测试后，运行单元测试的方法是在my_test.py的最后加上两行代码 12if __name__ == '__main__': unittest.main() 这样就可以把my_test.py当做正常的python脚步运行。 另外一个方法是在命令行通过-m unittest直接运行单元测试，跟运行pdb方式类似。 setUp()和tearDown() 单元测试中提供给两个特殊的setUp()和tearDown()方法。这两个方法会在每调用一个测试方法的前后分别被执行。 示例 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849import unittestclass Student(object): def __init__(self, name, score): self.name = name self.score = score def get_grade(self): level = 'C' if self.score &gt;= 60: level = 'B' if self.score &gt;= 80: level = 'A' return levelclass TestStudent(unittest.TestCase): def test_80_to_100(self): s1 = Student('Bart', 80) s2 = Student('Lisa', 100) self.assertEqual(s1.get_grade(), 'A') self.assertEqual(s2.get_grade(), 'A') def test_60_to_80(self): s1 = Student('Bart', 60) s2 = Student('Lisa', 79) self.assertEqual(s1.get_grade(), 'B') self.assertEqual(s2.get_grade(), 'B') def test_0_to_60(self): s1 = Student('Bart', 0) s2 = Student('Lisa', 59) self.assertEqual(s1.get_grade(), 'C') self.assertEqual(s2.get_grade(), 'C') def test_invalid(self): s1 = Student('Bart', None) s2 = Student('Lisa', '101') with self.assertRaises(Exception): s1.get_grade() with self.assertRaises(Exception): s2.get_grade()if __name__ == '__main__': unittest.main() # suite = unittest.TestLoader().loadTestsFromTestCase(TestStudent) # unittest.TextTestRunner(verbosity=2).run(suite) 建议在项目中建一个test模块，里面编写各个功能的单元测试，每次修改代码后跑通单元测试再提交给测试组测试。单元测试能极大的避免简单的bug。大大减少bug数量。]]></content>
      <categories>
        <category>编程基础</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>单元测试</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python并发框架tornado]]></title>
    <url>%2F2018%2F06%2F23%2FPython%E5%B9%B6%E5%8F%91%E6%A1%86%E6%9E%B6tornado%2F</url>
    <content type="text"><![CDATA[Tornado 介绍 Tornado是一个基于epoll IO复用模型的异步IO库。  tornado提供了ioloop用于支持TCP/UDP并发库，httpserver提供非阻塞Http Server。 基于tornado的异步TCP服务端12345678910111213141516171819202122232425262728293031323334353637383940414243#! /usr/bin/env pythonfrom tornado.tcpserver import TCPServerfrom tornado.ioloop import IOLoopclass Connection(object): def __init__(self, stream, address): self._stream = stream self._address = address self._stream.set_close_callback(self.on_close) self.read_message() print("Client connection from:", address) def read_message(self): self._stream.read_until(b'\n', self.reverse_messages) def reverse_messages(self, data): data = data.decode('utf8')[:-1] print("Recv:", data, self._address) data = data[-1::-1] + '\n' self.send_message(data) self.read_message() def send_message(self, data): self._stream.write(data.encode('utf8')) def on_close(self): print("Client close.", self._address)class ChatServer(TCPServer): def handle_stream(self, stream, address): print("New connection :", address, stream) Connection(stream, address)if __name__ == '__main__': print("Server start ......") server = ChatServer() server.listen(8000) IOLoop.instance().start() 此服务端将接收到数据，并反转字符串发送给所有用户。 使用两个nc连接8000端口并发送数据 12345$ nc 127.0.0.1 8000hahaahahhelloolleh 服务端输出 12345678Server start ......New connection : ('127.0.0.1', 37388) &lt;tornado.iostream.IOStream object at 0x7f3f99f3da90&gt;Client connection from: ('127.0.0.1', 37388)Recv: haha ('127.0.0.1', 37388)Recv: hello ('127.0.0.1', 37388)New connection : ('127.0.0.1', 37400) &lt;tornado.iostream.IOStream object at 0x7f3f9376e7f0&gt;Client connection from: ('127.0.0.1', 37400)Recv: haha ('127.0.0.1', 37400) 在tcpserver.py文件的第287:298行可以看到 123456789101112if self.ssl_options is not None: stream = SSLIOStream(connection, max_buffer_size=self.max_buffer_size, read_chunk_size=self.read_chunk_size)else: stream = IOStream(connection, max_buffer_size=self.max_buffer_size, read_chunk_size=self.read_chunk_size)future = self.handle_stream(stream, address) if future is not None: IOLoop.current().add_future(gen.convert_yielded(future), lambda f: f.result()) _stream是一个tornado封装的IOSStream或SSLIOSStream对象。 IOSStream类的read_until(self, delimiter, callback=None, max-bytes=None)方法提供读取数据直到获取到delimiter。上面设置为读取到’\n’数据进行操作。 IOSStream类还提供了read_bytes()方法来读取指定数量的字节。 IOSStream类提供了write()方法来将指定的buffer写入socket并持续检测直到buffer被发送。 ChatServer继承与TCPServer类。必须复写hande_stream方法。该方法在TCPServer接到新连接时会被调用，且传入连接的stream数据流和address连接地址。 异步HTTP服务器创建一个简单的服务器12345678910111213141516171819import tornado.ioloopimport tornado.webclass MainHandler(tornado.web.RequestHandler): def get(self): query = self.get_argument('q', 'World') self.write("&lt;h1&gt;Hello, %s&lt;/h1&gt;" % query) def post(self): query = self.get_argument('name', 'Luna') self.write('Hi, ' + query)if __name__ == "__main__": application = tornado.web.Application([ (r"/", MainHandler), ]) application.listen(8888) tornado.ioloop.IOLoop.current().start() 使用curl请求结果如下 12$ curl http://localhost:8888/?q=Luna&lt;h1&gt;Hello, Luna&lt;/h1&gt; 创建一个异步服务器123456789101112131415161718192021222324252627282930313233343536373839import tornado.httpserverimport tornado.ioloopimport tornado.optionsimport tornado.webimport tornado.httpclientimport tornado.genimport jsonfrom tornado.options import define, optionsdefine("port", default=8000, help="run on the given port", type=int)class IndexHandler(tornado.web.RequestHandler): @tornado.web.asynchronous @tornado.gen.engine def get(self): body = json.dumps(&#123;'name': 'L3una'&#125;) client = tornado.httpclient.AsyncHTTPClient() response = yield tornado.gen.Task( client.fetch, 'http://localhost:8888/', # 替换有效url method='POST', body=body, ) self.write(response.body) self.finish() def if __name__ == "__main__": tornado.options.parse_command_line() app = tornado.web.Application( handlers=[ (r"/", IndexHandler) ] ) http_server = tornado.httpserver.HTTPServer(app) http_server.listen(options.port) tornado.ioloop.IOLoop.instance().start() 使用curl请求http://localhost:8000/结果如下 12$ curl localhost:8000/Hi, Luna tornado建议使用Future来编写异步。 创建一个异步web服务器 tornado支持动态路由，即通过正则匹配url传入参数到对应类中。 tornado支持二级域名，可以自动将主域名的子目录转换为二级域名。 tornado支持RESTFUL API接口，通过tornado.web.RequestHandler类可以看到其中提供了head, get, post, delete, patch, put操作。 tornado还支持模板语言，跟django类似，使用&#123;%&#37;}将模板语句包起来，并且控制语句跟python语句格式基本相同。 tornado也支持cookie和CSRF等操作。 异步：tornado默认是单进程单线程，tornado推荐使用装饰器+Future实现Tornado异步非阻塞。 tornado异步依赖两个装饰器 tornado.web.asynchronous tornado.gen.coroutine tornado.web.asynchronous装饰器会让请求变成长连接方式，需要手动调用self.finish()才会响应请求。如果没有手动调用self.finish()该连接会一直保持pending状态。 tornado.gen.coroutine装饰器使函数返回一个Future，在调用结束时会调用Future.set_result()将return的返回值设置到result中，内部使用fetch_coroutine调用直到无返回值为止。 tornado.concurrent.Future提供一个add_done_callback()方法用来时future调用结束后调用回调方法。 tornado.gen.Task用来执行一个异步任务，使用yield抛出结果。 1234567891011121314151617181920212223242526272829303132333435363738394041import tornado.ioloopimport tornado.optionsimport tornado.webfrom tornado.concurrent import Futurefrom tornado import genimport jsonfrom tornado.options import define, optionsdefine("port", default=8000, help="run on the given port", type=int)class IndexHandler(tornado.web.RequestHandler): @tornado.web.asynchronous @tornado.gen.coroutine def get(self): future = self.sleep() # 等同于 # future = Future() # future.set_result('Luna') future.add_done_callback(self.welcome) # 等同于 # result = tornado.gen.Task(self.sleep) # self.write('&lt;h1&gt;Welcome %s!&lt;/h1&gt;' % result) # 使用tornado.gen.coroutine注解来自动生成一个future。并且在future执行完后调用add_done_callback中的方法 @gen.coroutine def sleep(self): return 'Luna' def welcome(self, future): result = future.result() self.write('&lt;h1&gt;Welcome %s!&lt;/h1&gt;' % result)if __name__ == "__main__": tornado.options.parse_command_line() handlers=[ (r"/", IndexHandler) ] http_server = tornado.web.Application(handlers) http_server.listen(options.port) tornado.ioloop.IOLoop.instance().start() web上访问可以看到 在tornadoweb github中可以查看各种类型的demo：tornado]]></content>
      <categories>
        <category>编程基础</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>并发</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux下systemctl脚本编写规则]]></title>
    <url>%2F2018%2F06%2F20%2FLinux%E4%B8%8Bsystemctl%E8%84%9A%E6%9C%AC%E7%BC%96%E5%86%99%E8%A7%84%E5%88%99%2F</url>
    <content type="text"><![CDATA[目前大量的Linux系统采用systemd作为系统启动方式。 下面介绍使用如何编写自定义systemctl服务脚本，添加自启动服务。 systemd介绍http://www.ibm.com/developerworks/cn/linux/1407_liuming_init3/index.html systemctl命令介绍systemctl {OPTIONS} {COMMAND}，可以通过systemctl –help查看详情 常用操作 操作 功能 start 开启该服务 stop 停止服务 restart 重启服务 enable 使该服务开机自启动 disable 不让服务开机自启动 list-jobs 显示所有systemd服务 list-dependencies –after/before sshd.service 显示sshd所有依赖列表 例如: 123systemctl enable nginx.service # 将nginx.service服务加入开机自启动列表，自启动脚本位于/etc/systemd/system/目录中systemctl start nginx.service # 开启nginx.service服务systemctl restart NetworkManager.service # 重启NetworkManager.service服务 systemctl编写规则例如我们要添加一个名为myserver.service的服务。 123456789101112131415161718[Unit]Description=description # 描述After=syslog.targetAfter=network.target[Service]Type=forking User=sysadmGroup=bh_watchdogPIDFile=/var/run/myserver.pidExecStart=/usr/bin/myserver startExecStop=/usr/bin/myserver stopExecReload=/usr/bin/myserver restartPrivateTmp=true[Install]WantedBy=multi-user.target [Unit]部分主要是对该服务的一个说明，内容包括Description和After。Description用于描述服务，After用域描述服务类别。 [Server]部分是服务的关键部分，该部分用于设置运行参数。Type=forking表示该服务为后台运行的形式，User表示执行该服务的角色，Group表示执行该服务的组。PIDFile为存放PID的文件路径，ExecStart为服务的具体运行命令，ExecReload为重启命令，ExecStop为停止命令，PrivateTmp=True表示给服务分配独立的临时空间。 注意: ExecStart,ExecStop,ExecReload等命令必须跟绝对路径，不能使用相对路径。 [Install]部分为服务安装的相关设置，可设置为多用户。 按照上面编写完成脚本后，需要以644的权限保存在/usr/lib/systemd/system/或/usr/lib/systemd/user/目录下。system目录不需要用户登录即可使用，user目录下的服务必须在用户登录情况下才能使用。 使用该systemctl管理该脚本 12345# systemctl执行出错可以使用systemctl status myservice.service查找错误原因systemctl start myserver.service # 启动myserver.service服务systemctl stop myserver.service # 停止myserver.service服务systemctl restart myserver.service # 重启myserver.service服务systemctl enable myserver.servcie # 将该服务添加到systemd自启动列表 成功运行并且添加到自启动，从此万事大吉。服务多为守护进程。 总结 systemd采用CGroup来管理进程生命周期，所以服务进程可以不用进行两次fork，进程创建的所有子进程都与该服务进程同属与一个组内。 服务进程不需要维护pid文件，也不需要调用setsid()来变为会话首领 systemd提供了日志功能，服务进程输出到stderr即可。 注意：由于使用了CGroup来管理进程生命周期，使用结束该服务进程时，所有子进程将被结束。]]></content>
      <categories>
        <category>折腾笔记</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>systemd</tag>
        <tag>systemctl</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[vim配置]]></title>
    <url>%2F2018%2F06%2F13%2Fvim%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[Linux下的文件编辑神器vim使用方法，记下此文，忘了就看看。 vim常用方法安装vim 12yum install vim #centosapt-get install vim #ubuntu 操作vim键位图 编辑模式 12345i 光标处编辑insert 光标编辑a 光标后开始编辑o 换行并编辑U 撤销编辑 ESC退出编辑模式 12345:q 退出文件:q! 强制退出文件:w 保存文件:wq 保存并退出:wq! 强制保存并退出文件 快速跳转 1234set nu 显示行号:num 快速跳转到第num行gg 快速跳转到首行G 快速跳转到尾行 光标移动 12345j/k/l/i 分别对应左下右上w 跳转到下一个单词开始位置b 跳转到上一个单词开始位置0 跳转到行首$ 跳转到行尾 复制yank 123456y 在使用v模式选定了某一块的时候，复制选定块到缓冲区用yy 复制整行(nyy或者yny ，复制n行，n为数字)y^ 复制当前到行头的内容； y$ 复制当前到行尾的内容； yw 复制一个word(nyw或者ynw，复制n个word，n为数字)yG 复制至档尾(nyG或者ynG，复制到第n行，例如1yG或者y1G，复制到档尾) 剪切 123456d 剪切选定块到缓冲区； dd 剪切整行 d^ 剪切至行首 d$ 剪切至行尾 dw 剪切一个word dG 剪切至档尾 粘贴 12p 小写p代表贴至游标后（下），因为游标是在具体字符的位置上，所以实际是在该字符的后面 P 大写P代表贴至游标前（上）]]></content>
      <categories>
        <category>折腾笔记</category>
      </categories>
      <tags>
        <tag>vim</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python创建Linux/Unix守护进程]]></title>
    <url>%2F2018%2F06%2F13%2FPython%E5%88%9B%E5%BB%BALinux-Unix%E5%AE%88%E6%8A%A4%E8%BF%9B%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[守护进程是一种生存周期较长的一种进程，他们独立于控制终端并且周期性的执行某种任务或者等待处理某些发生的时区。他们常常在系统引导时装入启动，在系统关闭时终止。大多数服务器都是用守护进程实现的，例如inetd,mysqld等。最后的d表示该进程为守护进程。 守护进程原理守护进程特点守护进程与后台进程区别： 后台运行程序，即加&amp;启动的程序 后台运行的程序拥有控制终端，守护进程没有 编写规则 调用umask将文件模式创建屏蔽字设置为0。 调用fork，然后使父进程退出，这样可以避免控制终端将Daemon放入后台执行。 调用setsid创建一个新绘画，这样可以将调用进程设置为新会话的首进程，成为一个新进程组的组长进程，没有控制终端。 将当前工作目录更改为跟目录，进程活动时，其工作目录所在的文件系统不能卸下。一般需要设置为跟妈目录。 关闭不在需要的文件描述符。进程从父进程哪里继承了打开的文件描述符。如不关闭，将会浪费系统资源，造成文件无法正确关闭等无法预知的错误。 某些守护进程打开/dev/null使其具有文件描述符0,1,2。使得任何一个试图读写标准输入、输出、标准出错的进程都不会产生任何效果。 处理SIGCHILD信号，处理SIGCHILD信号不是必须的，但是某些进程中，特别是服务器进程往往在请求到来时生成子进程处理请求。如果父进程不等待子进程结束，子进程将成为僵尸进程从而占用系统资源。父进程等待子进程结束会增大父进程负担，影响服务器并发性能。Linux下可以简单的讲SIGCHILD信号操作设置为SIG_IGN。 在控制终端输入ps -axj命令可以查看守护进程的信息。 守护进程没有控制终端，不能将错误写到标准输出上，大多数进程使用集中的守护进程出错syslog设施，该设施的接口时syslog函数。大多数syslog实现将使消息多时间处于队列中，如果此时间到达了重复消息，那么syslog进程将不会把他写到日志记录中，而是打印输出重复消息。 编写惯例守护进程使用锁文件通常存放在/var/run目录中； 若支持配置，通常房在/etc目录中； 守护进程可以用命令行启动，通常是系统初始化脚本； 如果守护进程有配置文件，那么读取文件后一般不会再查看它。 创建守护进程需要使用两次fork，第一次fork目的使保证调用setsid的调用进程不是进程组长。(setsid函数使实现于控制终端脱离的唯一方法)；setsid函数使进程成为新会话头河进程组长，并于控制终端断开链接；第二次调用fork目的使：即使守护进程将来打开一个终端设备，也不会自动获得控制终端。这样可以保证这次生成的进程不再是一个会话头。忽略SIGHUP信号的原因使，当第一次生成的子进程终止时，该会话中所有进程都会收到该信号。 实例123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122#!/usr/bin/env python3# daemon.pyimport osimport sysimport timeimport atexitimport signaldef daemonize(pidfile, *, stdin='/dev/null', stdout='/dev/null', stderr='/dev/null'): if os.path.exists(pidfile): raise RuntimeError('Already running') print('daemon starting...') # First fork (detaches from parent) try: if os.fork() &gt; 0: raise SystemExit(0) # Parent exit except OSError as e: raise RuntimeError('fork #1 failed.') os.chdir('/') os.umask(0) os.setsid() # Second fork (relinquish session leadership) try: if os.fork() &gt; 0: raise SystemExit(0) except OSError as e: raise RuntimeError('fork #2 failed.') # Flush I/O buffers sys.stdout.flush() sys.stderr.flush() # Replace file descriptors for stdin, stdout, and stderr with open(stdin, 'rb', 0) as f: os.dup2(f.fileno(), sys.stdin.fileno()) with open(stdout, 'ab', 0) as f: os.dup2(f.fileno(), sys.stdout.fileno()) with open(stderr, 'ab', 0) as f: os.dup2(f.fileno(), sys.stderr.fileno()) # Write the PID file with open(pidfile,'w') as f: print(os.getpid(),file=f) # Arrange to have the PID file removed on exit/signal atexit.register(lambda: os.remove(pidfile)) # Signal handler for termination (required) def sigterm_handler(signo, frame): raise SystemExit(1) signal.signal(signal.SIGTERM, sigterm_handler) print('daemon started.')def start(pidfile, stdin='/dev/null', stdout='/dev/null', stderr='/dev/null'): """ 开启守护进程 :return: """ try: daemonize(PIDFILE, stdout=stdout, stderr=stderr) except RuntimeError as e: print(e, file=sys.stderr) raise SystemExit(1) run()def stop(pidfile): if os.path.exists(pidfile): with open(pidfile, 'r') as f: pid = f.readline().strip() if pid: os.kill(int(pid), signal.SIGTERM) else: print('Not running', file=sys.stderr) raise SystemExit(1) for i in range(4): if os.path.exists(pidfile): time.sleep(0.5) else: break else: if os.path.exists(pidfile): os.remove(pidfile) print('daemon stop.')def restart(pidfile): stop(pidfile) start(pidfile) print('daemon restart.')def run(): import time sys.stdout.write('Daemon started with pid &#123;&#125;\n'.format(os.getpid())) while True: sys.stdout.write('Daemon Alive! &#123;&#125;\n'.format(time.ctime())) time.sleep(10)if __name__ == '__main__': PIDFILE = '/var/run/daemon/testd.pid' if len(sys.argv) != 2: print('Usage: &#123;&#125; [start|stop|restart]'.format(sys.argv[0]), file=sys.stderr) raise SystemExit(1) arg = sys.argv[1] if arg == 'start': start(PIDFILE, stdout='/tmp/daemon.log', stderr='/tmp/daemon.log') elif arg == 'stop': stop(PIDFILE) elif arg == 'restart': restart(PIDFILE) else: print('Unknown command &#123;!r&#125;'.format(sys.argv[1]), file=sys.stderr) raise SystemExit(1) 结果 12345678daemon.py startcat /var/run/daemon/testd.pid2882tail -f /tmp/daemon.logDaemon started with pid 2882Daemon Alive! Fri Oct 12 13:45:37 2012Daemon Alive! Fri Oct 12 13:45:47 2012... 一旦进程被正确分离，他会重新初始化标准I/O流执行用户指定的文件。简单的关闭sys.stdout并重新指定是不行的，因为不知道它是否全部都是用的sys.stdout atexit.register()注册了一个函数在Python解释器终止时执行。对于一个SIGTERM信号处理的定义同样需要被优雅的关闭。信号处理器简单的抛出了SystemExit()异常。如果没有该异常，终止信号会使不执行atexit.register()注册的清理操作的时候就杀掉解释器。 使用python-daemongithub地址:python-daemon 下载该daemon文件。 创建新自己的类继承daemon。 样例如下 1234567891011121314151617181920class MDaemon(Daemon): def __init__(self, *args, **kwargs): super(MDaemon, self).__init__(*args, **kwargs) def run(self): print(sys._getframe().f_lineno, 'run...') # 重写该run方法，将守护进程需要执行的事务放在此处。if len(sys.argv) != 2: print("Usage param &#123;start|stop|restart&#125;") raise SystemExit(0)arg = sys.argv[1]if arg in ('start', 'stop', 'restart'): d = MDaemon(pidfile='/var/run/mdaemon.pid', stdout='/var/log/mdaemon.log', stderr='/var/log/mdaemon.log') try: getattr(d, arg)() except KeyError as e: print(e) except Exception as e: print(e)]]></content>
      <categories>
        <category>编程基础</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>python</tag>
        <tag>守护进程</tag>
        <tag>Unix</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python2 Gevent]]></title>
    <url>%2F2018%2F06%2F06%2Fpython2%E5%BC%82%E6%AD%A5gevent%2F</url>
    <content type="text"><![CDATA[Gevent是一个基于libv的实现的一个python2协程并发库。 0x01 协程 （Coroutine）协程是一个轻量级线程，又叫微线程、纤程。 线程是计算机的最小执行单位，多线程程序在执行并发任务时是由CPU调度线程执行流程。 协程执行起来像是多线程，但却只有一个线程，共享资源不需要多线程的锁机制，执行效率比线程高。 协程是由一个进程执行，利用多核CPU最好采用多进程+协程。 0x02 Gevent核心gevent使用的主要模式时Greenlet，它以C扩展加python轻量级协程模式工作。Greenlet全部运行在主程序操作系统内部。 注意：在任何时刻，只有一个协程在运行。 协程的调度和multiprocess，threading等提供真正并行结构的库不同。这些库是真正的并行运行。 0x03 同步和异步基础用法 gevent.spawn()用来创建一个协程对象。 gevent.joinall()用来等来所有协程执行完毕。跟线程的join类似。 gevent.sleep()用来让协程睡眠挂起。 在python语法中，通过yield来切换协程。而在gevent里，上下文切换通过yielding来完成。 gevent.sleep(0)可以发出一个yielding信号来切换协程。 下面看一个示例 123456789101112131415161718#! /usr/bin/python3.6import geventdef foo(): print('Running in foo') gevent.sleep(0) print('Explicit context seitch to foo again')def bar(): print('Explicit context to bar') gevent.sleep(0) print('Implicit context switch back to bar')gevent.joinall([ gevent.spawn(foo), gevent.spawn(bar),]) 运行结果如下 1234Running in fooExplicit context to barExplicit context seitch to foo againImplicit context switch back to bar 可以看到foo和bar函数是并行运行的。 gevent.spawn(func, *args)传入参数，第一个为调用函数名，args为func需要的参数。 Greenlet状态就像任何其他成段代码，Greenlet也可能以不同的方式运行失败。 Greenlet可能未能成功抛出异常，不能停止运行，或消耗了太多的系统资源。 一个greenlet的状态通常是一个依赖于时间的参数。在greenlet中有一些标志， 让你可以监视它的线程内部状态： started – Boolean, 指示此Greenlet是否已经启动 ready() – Boolean, 指示此Greenlet是否已经停止 successful() – Boolean, 指示此Greenlet是否已经停止而且没抛异常 value – 任意值, 此Greenlet代码返回的值 exception – 异常, 此Greenlet内抛出的未捕获异常 程序停止当主程序收到一个SIGOUT信号时，不能成功的做yield操作可能会意外的挂起程序执行，这会导致产生僵尸进程，他需要在python解释器之外被kill掉。 通用的解决此问题的模式就是在主程序中监听一个SIGOUT信号，在程序退出时调用gevent.shutdown。 猴子补丁（Monkey pathing）猴子补丁使用monkey.path_socket()这个方法即可改变python标准库。 12345678910111213import socketprint(socket.socket)print("After monkey patch")from gevent import monkeymonkey.patch_socket()print(socket.socket)import selectprint(select.select)monkey.patch_select()print("After monkey patch")print(select.select) python运行环境允许在运行时修改大部分对象，类，函数，包括模块。随意修改基础环境会带来很多“隐式的副作用”，出现这些问题极难调试。在极端的情况下必须修改python基础库式，可以使用猴子补丁。gevent能够修改标准库里大部分阻塞式系统调用，包括socket，ssl，threading，select等模块，让他们变为协作式运行。 注意：所有基于协程的并发都不能使用sleep()函数，sleep()函数会阻塞整个线程，应该使用协程库自带的睡眠函数。 参考文献Gevent 程序员指南 gevent官方文档]]></content>
      <categories>
        <category>编程基础</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>并发</tag>
        <tag>协程</tag>
        <tag>gevent</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python3异步IO]]></title>
    <url>%2F2018%2F06%2F05%2FPython3%E5%BC%82%E6%AD%A5IO%2F</url>
    <content type="text"><![CDATA[asyncio是python3.4后引入的标准库。内置了对异步IO的支持。 python3.5还引入了async和await使asyncio更容易使用。 asyncio 基础 asyncio编程模式是一个消息循环，从asyncio模块中取出一个EventLoop的引用，然后把需要执行的协程放到EventLoop中执行，就实现了IO。 1234567891011121314import asyncio@asyncio.coroutinedef hello(): print("Hello world!") # 异步调用asyncio.sleep(1): r = yield from asyncio.sleep(1) print("Hello again!")# 获取EventLoop:loop = asyncio.get_event_loop()# 执行coroutineloop.run_until_complete(hello())loop.close() 执行结果 123Hello world!# 等待1秒Hello again! `@asyncio.coroutine注解表示hello()`函数为一个协程函数。 使用asyncio.sleep()可以让协程睡眠，EventLoop则会切换到其他协程继续执行达到异步效果。 asyncio.open_connection()异步网络连接 open_connection()语法如下 1open_connection(host=None, port=None, *, loop=None, limit=65536, **kwds) host: 服务器域名 port: 服务器端口 1234567891011121314151617181920212223import asyncio@asyncio.coroutinedef wget(host): print('wget %s...' % host) connect = asyncio.open_connection(host, 80) reader, writer = yield from connect header = 'GET / HTTP/1.0\r\nHost: %s\r\n\r\n' % host writer.write(header.encode('utf-8')) yield from writer.drain() while True: line = yield from reader.readline() if line == b'\r\n': break print('%s header &gt; %s' % (host, line.decode('utf-8').rstrip())) # Ignore the body, close the socket writer.close()loop = asyncio.get_event_loop()tasks = [wget(host) for host in ['www.sina.com.cn', 'www.sohu.com', 'www.163.com']]loop.run_until_complete(asyncio.wait(tasks))loop.close() 结果 12345678910111213141516wget www.sohu.com...wget www.sina.com.cn...wget www.163.com...(等待一段时间)(打印出sohu的header)www.sohu.com header &gt; HTTP/1.1 200 OKwww.sohu.com header &gt; Content-Type: text/html...(打印出sina的header)www.sina.com.cn header &gt; HTTP/1.1 200 OKwww.sina.com.cn header &gt; Date: Wed, 20 May 2015 04:56:33 GMT...(打印出163的header)www.163.com header &gt; HTTP/1.0 302 Moved Temporarilywww.163.com header &gt; Server: Cdn Cache Server V2.0... 此为3个连接由一个线程通过coroutine并发完成。 async/awaitasync和await是python3.5后引入的新语法。原本定义协程函数使用`@asyncio.coroutine注解，现在只需要在函数定义前加上async`即可。 123456789101112import asyncioasync def hello(): print("Hello world!") r = await asyncio.sleep(1) print("Hello again!")# 获取EventLoop:loop = asyncio.get_event_loop()# 执行coroutineloop.run_until_complete(hello())loop.close() 可以发现使用async/awati代码更加易读简洁。 aiohttpsyncio可以实现单线程并发IO操作，asyncio实现了TCP/UDP/SSL等协议，aiohttp则是基于asyncio实现的HTTP框架。 安装aiohttp 1pip install aiohttp 实例为一个HTTP服务器，可以处理/和/hello/{name}路由 12345678910111213141516171819202122232425import asynciofrom aiohttp import webasync def index(request): # 返回一个web响应 return web.Response(body=b'&lt;h1&gt;Index&lt;/h1&gt;', content_type='text/html')async def hello(request): text = '&lt;h1&gt;hello, %s&lt;/h1&gt;' % request.match_info['name'] return web.Response(body=text.encode('utf8'), content_type='text/html')async def init(loop): # 创建一个web容器 app = web.Application(loop=loop) # 添加web路由 app.router.add_route('GET', '/', index) app.router.add_route('GET', '/hello/&#123;name&#125;', hello) # 绑定监听地址并创建web服务 srv = await loop.create_server(app.make_handler(), '127.0.0.1', 8000) return srvloop = asyncio.get_event_loop()loop.run_until_complete(init(loop))loop.run_forever() 这样既实现了一个简单的web服务器 在asyncio中使用阻塞函数在程序中包含大量的阻塞函数，我们不能把所有的阻塞函数改为异步操作。而阻塞函数会使协程的流程阻塞掉，从而变成同步操作。 run_in_executor()方法我们可以使用run_in_executor()方法来调用操作。 1AbstractEventLoop.run_in_executor(executor, func, *args) executor 参数应该是一个 Executor 实例。如果为 None，则使用默认 executor。 func 就是要执行的函数 args 就是传递给 func 的参数 使用事件循环的run_in_executor()方法，asyncio的事件循环在背后维护着一个ThreadPoolExecutor对象，我们可以调用run_in_executor方法，把我们要执行的操作发给它，让事件循环来维护我们的耗时操作。 下列实例使用time.sleep()来作为阻塞函数 123456789101112131415161718192021222324252627import asyncioimport datetimeimport randomimport timeasync def run(event): print("start:", event) loop = asyncio.get_event_loop() try: delay_time = random.randint(0, 20) / 10.0 # await loop.run_in_executor(None, time.sleep, delay_time) executor = futures.ThreadPoolExecutor(max_workers=20) await loop.run_in_executor(executor, time.sleep, delay_time) # executor.submit(self.do_task, task) except Exception as e: print(e) print("use time:", delay_time, "stop:", event)url_list = ["aaa", "bbb", "ccc", "ddd", "eee", "fff"]tasks = [asyncio.ensure_future(run(url)) for url in url_list]start_time = datetime.datetime.now()loop = asyncio.get_event_loop()loop.run_until_complete(asyncio.wait(tasks))stop_time = datetime.datetime.now()print("use all time:", stop_time - start_time) 运行结果，可以看出所有协程的time.sleep一共耗费1.8秒时间 12345678910111213start: aaastart: bbbstart: cccstart: dddstart: eeestart: fffuse time: 0.0 stop: fffuse time: 0.7 stop: aaause time: 1.0 stop: ddduse time: 1.1 stop: eeeuse time: 1.3 stop: bbbuse time: 1.8 stop: cccuse all time: 0:00:01.804283]]></content>
      <categories>
        <category>编程基础</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>异步IO</tag>
        <tag>并发</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python socket网络编程]]></title>
    <url>%2F2018%2F06%2F05%2Fpython%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[所有语言的socket编程流程基本一致。都是服务端创建套接字，绑定端口，监听端口，接收套接字连接，分发连接到其他线程处理。客户端创建套接字，连接服务端，收发数据。 TCP下面来看一个简单的TCP服务端客户端通信程序。 服务端 12345678910111213141516171819202122232425262728import socketimport asyncioimport timeasync def work(sock, addr): print('Accept new connection from %s:%s...' % addr) sock.send(b'Welcome!') while True: data = sock.recv(1024) time.sleep(0.01) if not data or data.decode('utf8') == 'quit': break sock.send(('Hello, %s!' % data.decode('utf8')).encode('utf8')) sock.close() print('Connection from %s:%s closed' % addr)loop = asyncio.get_event_loop()try: s = socket.socket(socket.AF_INET, socket.SOCK_STREAM) s.bind(('127.0.0.1', 10011)) s.listen(5) while True: sock, addr = s.accept() loop.run_until_complete(work(sock, addr))except Exception as e: print(e)finally: loop.close() 客户端 1234567891011121314151617181920212223242526272829import socketimport threadingimport randomchars = 'qwertyuiikhfsfgxcvcbnm'length = len(chars)def client(): sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM) sock.connect(('127.0.0.1', 10011)) data = sock.recv(1024).decode('utf8') for i in range(3): start = (i + random.randint(0, length)) % length data = chars[start: (start+4) % length] sock.send(data.encode('utf8')) print(sock.recv(1024).decode('utf8')) sock.send(b'quit') sock.close()clients = []for i in range(3): t = threading.Thread(target=client) t.start() clients.append(t)for i in clients: i.join() 运行结果 服务端 123456Accept new connection from 127.0.0.1:62178...Connection from 127.0.0.1:62178 closedAccept new connection from 127.0.0.1:62179...Connection from 127.0.0.1:62179 closedAccept new connection from 127.0.0.1:62180...Connection from 127.0.0.1:62180 closed 客户端 123456789Hello, gxcv!Hello, erty!Hello, wert!Hello, iikh!Hello, rtyu!Hello, ikhf!Hello, fsfg!Hello, tyui!Hello, iikh! 可以看到由于采用了并发模式，通信的数据是乱序的。 UDPUDP流程跟上面TCP类似。 创建UDP套接字 1s = socket.socket(socket.AF_IENT, socket.SOCK_DGRAM) 接收数据：UDP套接字接收不仅可以使用recv函数，还可以使用recvfrom函数。recvfrom函数可以返回客户端的地址与端口。 1data, addr = s.recvfrom(1024) 发送数据：UDP套接字发送数据不适用send函数，而使用sendto函数， 1s.sendto(data, ('127.0.0.1', 10011)) 总结TCP基于长连接的，稳定可靠。UDP是协议传输，不稳定。 注意：recv与recvfrom都是阻塞函数。]]></content>
      <categories>
        <category>编程基础</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>socket</tag>
        <tag>TCP</tag>
        <tag>UDP</tag>
        <tag>网络编程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python模拟请求requests模块]]></title>
    <url>%2F2018%2F06%2F05%2Fpython%E6%A8%A1%E6%8B%9F%E8%AF%B7%E6%B1%82requests%E6%A8%A1%E5%9D%97%2F</url>
    <content type="text"><![CDATA[python具有很方便的库可以轻松的模拟http请求。 python2内置的有urllib和urllib2；python3将urllib2合并到了urllib中。 下面我们来了解下requests这个第三方模块。次模块更加易用。 安装requests如果安装了anaconda，requests就可以可以使用了。否则，需要在命令行下通过pip安装。 1pip install requests 如果遇上权限不够，加上sudo后重试。 使用requests requests提供很方便的方式模拟一个GET请求访问页面。 1234567891011121314&gt;&gt;&gt; import requests&gt;&gt;&gt; r = requests.get('https://www.baidu.com/')&gt;&gt;&gt; r.status_code200&gt;&gt;&gt; r.text'&lt;!DOCTYPE html&gt;\r\n&lt;!--STATUS OK--&gt;&lt;html&gt; &lt;head&gt;&lt;meta http-equiv=content-type content=text/html;charset=utf-8&gt;&lt;meta http-equiv=X-UA-Compatible content=IE=Edge&gt;&lt;meta content=always name=referrer&gt;&lt;link rel=stylesheet type=text/css href=https://ss1.bdstatic.com/5eN1bjq8AAUYm2zgoY3K/r/www/cache/bdorz/baidu.min.css&gt;&lt;title&gt;ç\x99¾åº¦ä¸\x80ä¸\x8bï¼\x8cä½\xa0å°±ç\x9f¥é\x81\x93&lt;/title&gt;&lt;/head&gt; &lt;body link=#0000cc&gt; &lt;div id=wrapper&gt; &lt;div id=head&gt; &lt;div class=head_wrapper&gt; &lt;div class=s_form&gt; &lt;div class=s_form_wrapper&gt; &lt;div id=lg&gt; &lt;img hidefocus=true src=//www.baidu.com/img/bd_logo1.png width=270 height=129&gt; &lt;/div&gt; &lt;form id=form name=f action=//www.baidu.com/s class=fm&gt; &lt;input type=hiddenname=bdorz_come value=1&gt; &lt;input type=hidden name=ie value=utf-8&gt; &lt;input type=hidden name=f value=8&gt; &lt;input type=hidden name=rsv_bp value=1&gt; &lt;input type=hidden name=rsv_idx value=1&gt; &lt;input type=hidden name=tn value=baidu&gt;&lt;span class="bg s_ipt_wr"&gt;&lt;input id=kw name=wd class=s_ipt value maxlength=255 autocomplete=off autofocus=autofocus&gt;&lt;/span&gt;&lt;span class="bg s_btn_wr"&gt;&lt;input type=submit id=su value=ç\x99¾åº¦ä¸\x80ä¸\x8b class="bg s_btn" autofocus&gt;&lt;/span&gt; &lt;/form&gt; &lt;/div&gt; &lt;/div&gt; &lt;div id=u1&gt; &lt;a href=http://news.baidu.com name=tj_trnews class=mnav&gt;æ\x96°é\x97»&lt;/a&gt; &lt;a href=https://www.hao123.com name=tj_trhao123 class=mnav&gt;hao123&lt;/a&gt; &lt;a href=http://map.baidu.com name=tj_trmap class=mnav&gt;å\x9c°å\x9b¾&lt;/a&gt; &lt;a href=http://v.baidu.com name=tj_trvideo class=mnav&gt;è§\x86é¢\x91&lt;/a&gt; &lt;a href=http://tieba.baidu.com name=tj_trtieba class=mnav&gt;è´´å\x90§&lt;/a&gt; &lt;noscript&gt; &lt;a href=http://www.baidu.com/bdorz/login.gif?login&amp;amp;tpl=mn&amp;amp;u=http%3A%2F%2Fwww.baidu.com%2f%3fbdorz_come%3d1 name=tj_login class=lb&gt;ç\x99»å½\x95&lt;/a&gt; &lt;/noscript&gt; &lt;script&gt;document.write(\'&lt;a href="http://www.baidu.com/bdorz/login.gif?login&amp;tpl=mn&amp;u=\'+ encodeURIComponent(window.location.href+ (window.location.search === "" ? "?" : "&amp;")+ "bdorz_come=1")+ \'" name="tj_login" class="lb"&gt;ç\x99»å½\x95&lt;/a&gt;\');\r\n &lt;/script&gt; &lt;a href=//www.baidu.com/more/ name=tj_briicon class=bri style="display: block;"&gt;æ\x9b´å¤\x9aäº§å\x93\x81&lt;/a&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div id=ftCon&gt; &lt;div id=ftConw&gt; &lt;p id=lh&gt; &lt;a href=http://home.baidu.com&gt;å\x85³äº\x8eç\x99¾åº¦&lt;/a&gt; &lt;a href=http://ir.baidu.com&gt;About Baidu&lt;/a&gt; &lt;/p&gt; &lt;p id=cp&gt;&amp;copy;2017&amp;nbsp;Baidu&amp;nbsp;&lt;a href=http://www.baidu.com/duty/&gt;ä½¿ç\x94¨ç\x99¾åº¦å\x89\x8då¿\x85è¯»&lt;/a&gt;&amp;nbsp; &lt;a href=http://jianyi.baidu.com/ class=cp-feedback&gt;æ\x84\x8fè§\x81å\x8f\x8dé¦\x88&lt;/a&gt;&amp;nbsp;äº¬ICPè¯\x81030173å\x8f·&amp;nbsp; &lt;img src=//www.baidu.com/img/gs.gif&gt; &lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;/body&gt; &lt;/html&gt;\r\n' 对于带参数的url，传入一个dict作为params参数： 12345&gt;&gt;&gt; r = requests.get('https://www.douban.com/search', params=&#123;'q': 'python'&#125;)&gt;&gt;&gt; r.url'https://www.douban.com/search?q=python'&gt;&gt;&gt; r.encoding'utf-8' requests自动检测编码，可以使用encoding属性查看 使用content属性可以获取返回结果的bytes对象。 12345&gt;&gt;&gt; r.contentb'&lt;!DOCTYPE html&gt;\n&lt;html lang="zh-cmn-Hans" class=""&gt;\n&lt;head&gt;\n &lt;meta http-equiv="Content-Type" content="text/html; charset=utf-8"&gt;\n &lt;meta name="renderer" content="webkit"&gt;\n &lt;meta name="referrer" content="always"&gt;\n &lt;title&gt;\n \xe6\x90\x9c\xe7\xb4\xa2: python\n&lt;/title&gt;\n \n \n &lt;meta http-equiv="Pragma" content="no-cache"&gt;\n &lt;meta http-equiv="Expires" content="Sun, 6 Mar 2005 01:00:00 GMT"&gt;\n \n&lt;link rel="search" type="application/opensearchdescription+xml" title="\xe8\xb1\x86\xe7\x93\xa3\xe6\x90\x9c\xe7\xb4\xa2" href="/opensearch"&gt;\n\n ...&gt;&gt;&gt; 如果返回值是一个特定类型的响应，例如json。可以直接获取使用json方法直接获取r.json()。 传入http header。 get()方法支持传入一个dict作为headers参数。 123&gt;&gt;&gt; r = requests.get('https://www.douban.com/', headers=&#123;'User-Agent': 'Mozilla/5.0 (iPhone; CPU iPhone OS 11_0 like Mac OS X) AppleWebKit'&#125;)&gt;&gt;&gt; r.text'&lt;!DOCTYPE html&gt;\n&lt;html&gt;\n&lt;head&gt;\n&lt;meta charset="UTF-8"&gt;\n &lt;title&gt;豆瓣(手机版)&lt;/title&gt;...' 使用requests.post()方法来模拟POST请求，用法于requests.get()相同，传入一个dict作为data参数。 1&gt;&gt;&gt; r = requests.post('https://accounts.douban.com/login', data=&#123;'form_email': 'abc@example.com', 'form_password': '123456'&#125;) requests默认使用application/x-www-form-urlencoded对POST数据编码。如果要传递JSON数据，可以直接传入json参数： 12params = &#123;'key': 'value'&#125;r = requests.post(url, json=params) # 内部自动序列化为JSON 上传文件需要更复杂的编码格式，但是requests把它简化成files参数： 12&gt;&gt;&gt; upload_files = &#123;'file': open('report.xls', 'rb')&#125;&gt;&gt;&gt; r = requests.post(url, files=upload_files) 注意：读取文件是必须使用rb，这样获取的bytes长度才是文件长度。 把post()方法替换为put(),delete()等RESTFUL方法请求资源。 获取HTTP响应内容 headers属性可以获取响应头 cookies属性可以获取cookie 123456&gt;&gt;&gt; r.headers&#123;Content-Type': 'text/html; charset=utf-8', 'Transfer-Encoding': 'chunked', 'Content-Encoding': 'gzip', ...&#125;&gt;&gt;&gt; r.headers['Content-Type']'text/html; charset=utf-8' &gt;&gt;&gt; r.cookies['ts']'example_cookie_12345' 使用chardet探测字符编码anaconda自带了chardet库；可以使用pip安装 1pip install chardet 使用对bytes类型进行编码检测 12&gt;&gt;&gt; chardet.detect(b'Hello, world!')&#123;'encoding': 'ascii', 'confidence': 1.0, 'language': ''&#125; encoding表示探测到的编码类型，confidence表示检测的概率，language表示字符串语言。]]></content>
      <categories>
        <category>编程基础</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>requests</tag>
        <tag>chardet</tag>
        <tag>字符检测</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python正则表达式]]></title>
    <url>%2F2018%2F06%2F04%2FPython%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[在对字符串进行复杂匹配时，使用正则表达式会大大的提高效率并且容易使用。 正则表达式是一种匹配规范，大多数高级语言都有正则表达式模块。 正则表达式匹配规则 字符 描述 \ 将下一个字符标记为一个特殊字符、或一个原义字符、或一个 向后引用、或一个八进制转义符。例如，’n’ 匹配字符 “n”。’\n’ 匹配一个换行符。序列 ‘\‘ 匹配 “\” 而 “(“ 则匹配 “(“。 ^ 匹配输入字符串的开始位置。如果设置了 RegExp 对象的 Multiline 属性，^ 也匹配 ‘\n’ 或 ‘\r’ 之后的位置。 $ 匹配输入字符串的结束位置。如果设置了RegExp 对象的 Multiline 属性，$ 也匹配 ‘\n’ 或 ‘\r’ 之前的位置。 * 匹配前面的子表达式零次或多次。例如，zo 能匹配 “z” 以及 “zoo”。 等价于{0,}。 + 匹配前面的子表达式一次或多次。例如，’zo+’ 能匹配 “zo” 以及 “zoo”，但不能匹配 “z”。+ 等价于 {1,}。 ? 匹配前面的子表达式零次或一次。例如，”do(es)?” 可以匹配 “do” 或 “does” 。? 等价于 {0,1}。 {n} n 是一个非负整数。匹配确定的 n 次。例如，’o{2}’ 不能匹配 “Bob” 中的 ‘o’，但是能匹配 “food” 中的两个 o。 {n,} n 是一个非负整数。至少匹配n 次。例如，’o{2,}’ 不能匹配 “Bob” 中的 ‘o’，但能匹配 “foooood” 中的所有 o。’o{1,}’ 等价于 ‘o+’。’o{0,}’ 则等价于 ‘o*’。 {n,m} m 和 n 均为非负整数，其中n &lt;= m。最少匹配 n 次且最多匹配 m 次。例如，”o{1,3}” 将匹配 “fooooood” 中的前三个 o。’o{0,1}’ 等价于 ‘o?’。请注意在逗号和两个数之间不能有空格。 ? 当该字符紧跟在任何一个其他限制符 (*, +, ?, {n}, {n,}, {n,m}) 后面时，匹配模式是非贪婪的。非贪婪模式尽可能少的匹配所搜索的字符串，而默认的贪婪模式则尽可能多的匹配所搜索的字符串。例如，对于字符串 “oooo”，’o+?’ 将匹配单个 “o”，而 ‘o+’ 将匹配所有 ‘o’。 . 匹配除换行符（\n、\r）之外的任何单个字符。要匹配包括 ‘\n’ 在内的任何字符，请使用像”(.\&#124;\n)“的模式。 (pattern) 匹配 pattern 并获取这一匹配。所获取的匹配可以从产生的 Matches 集合得到，在VBScript 中使用 SubMatches 集合，在JScript 中则使用 $0…$9 属性。要匹配圆括号字符，请使用 ‘(‘ 或 ‘)‘。 (?:pattern) 匹配 pattern 但不获取匹配结果，也就是说这是一个非获取匹配，不进行存储供以后使用。这在使用 “或” 字符 &#124;来组合一个模式的各个部分是很有用。例如， ‘industr(?:y\&#124;ies) 就是一个比 ‘industry\&#124;industries’ 更简略的表达式。 (?=pattern) 正向肯定预查（look ahead positive assert），在任何匹配pattern的字符串开始处匹配查找字符串。这是一个非获取匹配，也就是说，该匹配不需要获取供以后使用。例如，”Windows(?=95\&#124;98\&#124;NT\&#124;2000)”能匹配”Windows2000”中的”Windows”，但不能匹配”Windows3.1”中的”Windows”。预查不消耗字符，也就是说，在一个匹配发生后，在最后一次匹配之后立即开始下一次匹配的搜索，而不是从包含预查的字符之后开始。 (?!pattern) 正向否定预查(negative assert)，在任何不匹配pattern的字符串开始处匹配查找字符串。这是一个非获取匹配，也就是说，该匹配不需要获取供以后使用。例如”Windows(?!95\&#124;98\&#124;NT\&#124;2000)”能匹配”Windows3.1”中的”Windows”，但不能匹配”Windows2000”中的”Windows”。预查不消耗字符，也就是说，在一个匹配发生后，在最后一次匹配之后立即开始下一次匹配的搜索，而不是从包含预查的字符之后开始。 (?&lt;=pattern) 反向(look behind)肯定预查，与正向肯定预查类似，只是方向相反。例如，”(?&lt;=95&amp;#124;98&amp;#124;NT&amp;#124;2000)Windows“能匹配”2000Windows“中的”Windows“，但不能匹配”3.1Windows“中的”Windows“。 (?&lt;!pattern) 反向否定预查，与正向否定预查类似，只是方向相反。例如”(?&quot;能匹配&quot;3.1Windows&quot;中的&quot;Windows&quot;，但不能匹配&quot;2000Windows&quot;中的&quot;Windows`”。 x\&#124;y 匹配 x 或 y。例如，’z\&#124;food’ 能匹配 “z” 或 “food”。’(z\&#124;f)ood’ 则匹配 “zood” 或 “food”。 [xyz] 字符集合。匹配所包含的任意一个字符。例如， ‘[abc]’ 可以匹配 “plain” 中的 ‘a’。 [^xyz] 负值字符集合。匹配未包含的任意字符。例如， ‘[^abc]’ 可以匹配 “plain” 中的’p’、’l’、’i’、’n’。 [a-z] 字符范围。匹配指定范围内的任意字符。例如，’[a-z]’ 可以匹配 ‘a’ 到 ‘z’ 范围内的任意小写字母字符。 [^a-z] 负值字符范围。匹配任何不在指定范围内的任意字符。例如，’[^a-z]’ 可以匹配任何不在 ‘a’ 到 ‘z’ 范围内的任意字符。 \b 匹配一个单词边界，也就是指单词和空格间的位置。例如， ‘er\b’ 可以匹配”never” 中的 ‘er’，但不能匹配 “verb” 中的 ‘er’。 \B 匹配非单词边界。’er\B’ 能匹配 “verb” 中的 ‘er’，但不能匹配 “never” 中的 ‘er’。 \cx 匹配由 x 指明的控制字符。例如， \cM 匹配一个 Control-M 或回车符。x 的值必须为 A-Z 或 a-z 之一。否则，将 c 视为一个原义的 ‘c’ 字符。 \d 匹配一个数字字符。等价于 [0-9]。 \D 匹配一个非数字字符。等价于 [^0-9]。 \f 匹配一个换页符。等价于 \x0c 和 \cL。 \n 匹配一个换行符。等价于 \x0a 和 \cJ。 \r 匹配一个回车符。等价于 \x0d 和 \cM。 \s 匹配任何空白字符，包括空格、制表符、换页符等等。等价于 [ \f\n\r\t\v]。 \S 匹配任何非空白字符。等价于 [^ \f\n\r\t\v]。 \t 匹配一个制表符。等价于 \x09 和 \cI。 \v 匹配一个垂直制表符。等价于 \x0b 和 \cK。 \w 匹配字母、数字、下划线。等价于’[A-Za-z0-9_]’。 \W 匹配非字母、数字、下划线。等价于 ‘[^A-Za-z0-9_]’。 \xn 匹配 n，其中 n 为十六进制转义值。十六进制转义值必须为确定的两个数字长。例如，’\x41’ 匹配 “A”。’\x041’ 则等价于 ‘\x04’ &amp; “1”。正则表达式中可以使用 ASCII 编码。 \num 匹配 num，其中 num 是一个正整数。对所获取的匹配的引用。例如，’(.)\1’ 匹配两个连续的相同字符。 \n 标识一个八进制转义值或一个向后引用。如果 \n 之前至少 n 个获取的子表达式，则 n 为向后引用。否则，如果 n 为八进制数字 (0-7)，则 n 为一个八进制转义值。 \nm 标识一个八进制转义值或一个向后引用。如果 \nm 之前至少有 nm 个获得子表达式，则 nm 为向后引用。如果 \nm 之前至少有 n 个获取，则 n 为一个后跟文字 m 的向后引用。如果前面的条件都不满足，若 n 和 m 均为八进制数字 (0-7)，则 \nm 将匹配八进制转义值 nm。 \nml 如果 n 为八进制数字 (0-3)，且 m 和 l 均为八进制数字 (0-7)，则匹配八进制转义值 nml。 \un 匹配 n，其中 n 是一个用四个十六进制数字表示的 Unicode 字符。例如， \u00A9 匹配版权符号 (?)。 re模块简单匹配python使用re模块来支持正则表达式功能。 在匹配字符串是，python的字符串为r&#39;...&#39;表示字符串中的\不进行转义功能。 re.match()函数re.match函数尝试从字符串的起始位置匹配一个模块，如果不是起始位置匹配成功则返回None。 函数语法 1re.match(pattern. string, flags=0) pattern：匹配的正则表达式，字符串。 string：待匹配的字符串。 flags：正则表达式匹配标志位，如是否区分大小写等。 flags设置如下表 修饰符 描述 re.I 使匹配对大小写不敏感 re.L 做本地化识别（locale-aware）匹配 re.M 多行匹配，影响 ^ 和 $ re.S 使 . 匹配包括换行在内的所有字符 re.U 根据Unicode字符集解析字符。这个标志影响 \w, \W, \b, \B. re.X 该标志通过给予你更灵活的格式以便你将正则表达式写得更易于理解。 匹配后若结果不为空，可以使用group(num)或groups()函数来获取匹配表达式。 group(num=0): 匹配的整个表达式字符串，group可以一次输入多个组号，这时返回一个包含哪些组锁对应值的元组。 groups(): 返回一个包含所有小组字符串的元组。 实例： 123456789&gt;&gt;&gt; import re&gt;&gt;&gt; re.match('(\S+)@(\S+.com)', 'abc@qq.com').groups()('abc', 'qq.com')&gt;&gt;&gt; re.match('\S+@', 'abc@qq.com').group(0)'abc@'&gt;&gt;&gt; re.match('@\S+.com', 'abc@qq.com').group(0)Traceback (most recent call last): File "&lt;stdin&gt;", line 1, in &lt;module&gt;AttributeError: 'NoneType' object has no attribute 'group' re.search()方法re.search()方法会扫描整个字符串，并返回第一个成功的匹配项。 函数语法 1re.search(pattern, string, flags=0) 函数参数同re.match()。 匹配成功返回一个匹配对象，否则返回None。 可以使用group(num)或groups()匹配对象来获取匹配表达式。 123import re&gt;&gt;&gt; re.search('qq', 'abcqqrd@qq.com').group(0)'qq' 注意：re.match和re.search区别。re.match从字符串只能起始位置进行匹配，re.search匹配整个字符串。 检索和替换re.sub()替换re模块提供了re.sub方法用域替换字符串中的匹配项。 语法 1re.sub(patter, repl, string, count=0, flags) 参数： pattern：正则表达式的模式字符串。 repl：替换的字符串，也可以为一个函数。 string：要被查找替换的原字符串。 count：模式匹配后替换的最大次数，默认0表示替换所有匹配项。 flags: 匹配参数。 删除字符串中的所有数字： 12&gt;&gt;&gt; re.sub('\d+', '', 'ab4124dfd22_431 google 332 baidu 12')'abdfd_ google baidu ' 删除所有单数 1234567891011121314#!/usr/bin/pythonimport redef remove_odd(matched): a = int(matched.group()) % 2 return matched.group() if a else ''source = 'abc123fs43@aa21_43a'result1 = re.sub(r'\d+', '', source)result2 = re.sub(r'\d+', remove_odd, source)print(result1)print(result2) 结果如下 12abcfs@aa_aabc123fs43@aa21_43a re.compile()编译正则表达式re.compile()函数用来编译一个正则表达式，生成一个正则表达式对象(pattern)，供match()和search()、findall()这两个函数使用。 语法： 1re.compile(pattern[, flags]) 参数： pattern: 一个字符串形式的正则表达式 flags可选：匹配参数 1234567891011121314151617&gt;&gt;&gt; import re&gt;&gt;&gt; pattern = re.compile('\d+')&gt;&gt;&gt; mm = pattern.match('ab4124dfd22_431 google 332 baidu 12', 2, 10)&gt;&gt;&gt; mm.group()'4124'&gt;&gt;&gt; mm.start(0)2&gt;&gt;&gt; mm.end(0)6&gt;&gt;&gt; mm.span(0)(2, 6)&gt;&gt;&gt; mm = pattern.search('ab4124dfd22_431 google 332 baidu 12')&gt;&gt;&gt; mm.group()'4124'&gt;&gt;&gt; mm = pattern.findall('ab4124dfd22_431 google 332 baidu 12')&gt;&gt;&gt; mm['4124', '22', '431', '332', '12'] 返回的match对象提供了下列方法： group()：用于获得一个或多个分组匹配的字符串，当要获得整个字串是使用group()或group(0)即可。 start([group]): 用于获取分组匹配的子串在整个字符串中的起始位置，参数默认为0 end([group]): 用于获取分组匹配的子串在整个字符串中的结束位置，参数末尾为0 span([span]):用于返回(start(group), end(group))。 re.findall()匹配所有在字符串中找到正则表达式的所有子串，并返回一个列表。若没找到匹配，则返回空列表。 函数语法: 1findall(string[, pos[, endpos]]) string：待匹配的字符串 pos：可选参数，指定字符串的起始位置，默认为0 endpos：可选参数，指定字符串的结束位置，默认为字符串长度。 示例查找字符串中所有数字： 12345&gt;&gt;&gt; import re&gt;&gt;&gt; pattern = re.compile('\d+')&gt;&gt;&gt; mm = pattern.findall('ab4124dfd22_431 google 332 baidu 12')&gt;&gt;&gt; mm['4124', '22', '431', '332', '12'] re.finditer()匹配所有字串并返回一个迭代器。re.finditer用法于re.findall用法相同，区别就是re.finditer返回一个所有字串的迭代器。 123456789&gt;&gt;&gt; m = re.finditer('\d+', 'ab4124dfd22_431 google 332 baidu 12')&gt;&gt;&gt; for i in m:... print(i.group())... 41242243133212 re.split分割字符串re.split方法能够将匹配的子串用来分割原字符串。 123&gt;&gt;&gt; m = re.split('\d+', 'ab4124dfd22_431 google 332 baidu 12')&gt;&gt;&gt; m['ab', 'dfd', '_', ' google ', ' baidu ', '']]]></content>
      <categories>
        <category>编程基础</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>正则表达式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SQL注入浅谈]]></title>
    <url>%2F2018%2F06%2F01%2FSQL%E6%B3%A8%E5%85%A5%E6%B5%85%E8%B0%88%2F</url>
    <content type="text"><![CDATA[由于SQL注入的危害性和普遍性，防止SQL注入是一个开发者的基本素养。 SQL注入原理原理攻击者通过发送构造的特殊sql语句被sql解释器执行，通过执行这些恶意语句欺骗数据库执行，导致数据库信息泄露。 sql注入主要用在select查询时，insert,delete,update也可能能够利用，不过难度较大。 SQL注入分类 从参数类型可以分为两种：数字型和字符型 当发生注入点的参数为整数时，比如id，num，page等。这种形式为数字型注入。注入参数为字符串时则为字符型注入。 根据数据库返回结果分为回显注入、报错注入、盲注。 会先注入：可以直接在存在注入点的当前页面种获取返回结果。 报错注入：程序将数据的返回错误信息直接显示在页面中。可以根据构造特殊的语句从错误信息中获取想要的信息。 盲注：程序后端屏蔽了数据库错误信息，没有直接显示结果也没有报错信息，只能通过数据库的逻辑和延时函数来判断执行的结果。根据表现不同，盲注分为Boolean-based（布尔型注入）和Time-based（基于时间延迟）两种。 根据注入参数位置分为：GET注入、POST注入、COOKIE注入，http的header参数也可以引发注入。 测试SQL注入 数字型： 猜测SQL语句select col from table where id = 1; 1234http://www.domain.com/xx?id=1 假设id为存在注入的参数http://www.domain.com/xx?id=1&apos; 语句报错，可也使用双引号http://www.domain.com/xx?id=1 and 1=1 页面正常返回结果http://www.domain.com/xx?id=1 and 1=2 页面返回错误结果 上述几个测试步骤全部满足，则可能存在sql注入漏洞。 由于id=1在弱类型(asp/php)语言中会被id参数推到为int数据类型，而id=1 and 1=1则会被推到为string类型 而强类型(java/.net)这类强类型语言则会抛出异常。 字符型 字符型注入需要使用单/双引号进行闭合sql语句。 猜测SQL语句select col from table where name= &#39;xx&#39;; 1234http://www.domain.com/xx?name=xxx 假设name为存在注入的参数http://www.domain.com/xx?name=xxx' 语句报错http://www.domain.com/xx?name=xxx' and 1=1 and '1'='1 正常返回结果http://www.domain.com/xx?name=xxx' and 1=2 and '1'='1 返回错误结果 搜索型 猜测SQL语句select col from table where username like &#39;%k%&#39;; 1234http://www.domain.com/xx?search=test 假设search为存在注入的参数http://www.domain.com/xx?search=test` 语句报错http://www.domain.com/xx?search=test%' and 1=1 and '%'=' 页面正常返回结果http://www.domain.com/xx?search=test%' and 1=2 and '%'=' 页面返回错误 SQL攻击方式SQL注入常见的攻击方式有以下5种： Boolean-based blind SQL injection 布尔型注入 Error-based SQL injection 报错型注入 UNION query SQL injection 可联合查询注入 Stacked queries SQL injection 可多语句查询注入 Time-based blind SQL injection 基于时间延迟注入 Boolean-based blind SQL injection 布尔型注入通过判断页面放回情况获得想要的信息。 如下SQL注入 http://domain/view?id=1 and substring(version(), 1, 1)=5 如果服务的MySQL版本是5.x的话，页面会正常返回，可以通过这种方式获得MySQL的各类信息。 Error-based SQL injection 报错型注入如果页面能够输出SQL报错信息，则可以从报错信息种获得想要的信息。 http://www.domain.com/view?id=1%20AND%20(SELECT%207506%20FROM(SELECT%20COUNT(*),CONCAT(0x717a707a71,(SELECT%20MID((IFNULL(CAST(schema_name%20AS%20CHAR),0x20)),1,54)%20FROM%20INFORMATION_SCHEMA.SCHEMATA%20LIMIT%202,1),0x7178786271,FLOOR(RAND(0)*2))x%20FROM%20INFORMATION_SCHEMA.CHARACTER_SETS%20GROUP%20BY%20x)a) 在抛出SQL错误中会包含Duplicate entry ‘qzpzqttqxxbq1’ for key ‘group_key’这样的信息。 UNION query SQL injection 可联合查询注入通过UNION查询获取到所有想要的数据，前提是请求返回结果能输出SQL执行后查询到的内容。 http://www.domain.com/view?id=1 UNION ALL SELECT SCHEMA_NAME, DEFAULT_CHARACTER_SET_NAME FROM INFORMATION_SCHEMA.SCHEMATA Stacked queries SQL injection可多语句查询注入能够执行多条查询语句，非常危险。能够直接对数据库做更新操作。 http://www.domain.com/view?id=1;update t1 set content = &apos;aaaaaaaaa&apos; 在第二次请求时会发现content都被设置为aaaaaaaaa了。 基于时间延迟页面不会返回错误信息，不会输出UNION注入锁查出来的泄露信息。即可采用基于时间延迟的注入，即判断请求响应时间，此类注入获取信息速度慢，利用难度大。 http://www.domain.com/view?q=abc&apos; AND (SELECT * FROM (SELECT(SLEEP(5)))VCVe) OR 1 = &apos; SQL注入防御 数字型注入防御： 使用intval()函数进行过滤 字符串注入防御： 转义：htmlspecialchars()，mysqli_real_escape_string() 过滤：过滤关键字，过滤特殊字符。如无需要，将’”`过滤掉。]]></content>
      <categories>
        <category>信息安全</category>
      </categories>
      <tags>
        <tag>SQL注入</tag>
        <tag>web安全</tag>
        <tag>security</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python多线程]]></title>
    <url>%2F2018%2F06%2F01%2Fpython%E5%A4%9A%E7%BA%BF%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[多线程相比多进程，对资源消耗更少，使用同一进程资源，比多进程更加轻量高效。 Python的多线程是真正的Posix Thread，而不是模拟出的线程。 threading模块python标准库提供了两个多线程模块：_thread和threading，_thread是低级模块，threading是对_thread的封装。大多数情况下是用threading这个高级模块即可满足需求。 threading模块使用Thread对象即可创建一个实例，然后调用start()方法开始执行该线程，join()阻塞调用线程并等待子线程执行结束。 1234567891011121314import time, threadingdef loop(): print('thread %s is running' % threading.current_thread().name) for i in range(3): print('thread %s &gt;&gt;&gt; %s' % (threading.current_thread().name, i)) time.sleep(1) print('thread %s is ended.' % threading.current_thread().name)print('thread %s is running...' % threading.current_thread().name)t = threading.Thread(target=loop, name='LoopThread')t.start()t.join()print('thread %s ended.' % threading.current_thread().name) 结果如下 1234567thread MainThread is running...thread LoopThread is runningthread LoopThread &gt;&gt;&gt; 0thread LoopThread &gt;&gt;&gt; 1thread LoopThread &gt;&gt;&gt; 2thread LoopThread is ended.thread MainThread ended. 线程锁在多进程中，创建的每个子进程的资源是原进程的拷贝，每个进程互不干扰。而多线程则是多个线程共享同一个进程资源。对于多个线程同步使用共同资源时得执行加锁操作。 threading模块提供Lock()方法创建一个锁对象。lock.acquire()表示加锁操作，多个线程执行到该处时只有一个线程能成功获取锁，然后执行代码。其他线程继续等待直到获取锁。获得锁得线程使用完资源后必须得释放锁，否则其他线程将无法获取锁便永远等待下去成为死线程。 建议使用try...finally...确保锁一定会被释放。 下面是一个加锁实例 1234567891011121314151617181920212223242526272829import threading, timebalance = 0lock = threading.Lock()def change_it(n): global balance balance = balance + n balance = balance - ndef run_thread(n): for i in range(100000): # 先要获取锁: lock.acquire() try: # 放心地改吧: change_it(n) finally: # 改完了一定要释放锁: lock.release()t1 = threading.Thread(target=run_thread, args=(5,))t2 = threading.Thread(target=run_thread, args=(8,))t1.start()t2.start()t1.join()t2.join()print(balance) 结果如下 10 加锁会时异步执行变为同步执行，多线程执行锁内操作变为单线程执行，极大的降低执行效率。一般锁操作不要对大量逻辑进行加锁，只对资源操作进行加锁即可。 注意：多个线程对多种资源操作一定要防止产生死锁。 ThreadLocalThreadLocal是一个线程全局对象，每个线程互不影响。解决了参数在一个线程中各个函数之间互相传递的问题。使用local()方法创建一个实例。 12345678910111213141516171819import threadinglocal_school = threading.local()def process_student(): std = local_school.student print('Hello, %s (in %s)' % (std, threading.current_thread().name))def process_thread(name): local_school.student = name process_student()t1 = threading.Thread(target=process_thread, args=('Alice',), name='Thread-A')t2 = threading.Thread(target=process_thread, args=('Alice',), name='Thread-B')t1.start()t2.start()t1.join()t2.join() 结果如下 12Hello, Alice (in Thread-A)Hello, Alice (in Thread-B) GIL锁与多核CPUpython解释器执行代码时，会有个GIL全局锁，任何python代码执行前必须获得GIL锁，然后没执行100调字节码，解释器会自动释放GIL锁，让别的线程获得执行机会。意味着GIL给所有线程都上了锁，所以多个线程执行也只能使用单核CPU。 实际上：python可以使用多线程，但是无法有效利用多核，除非使用C扩展实现。 所以python使用多核CPU需要使用多进程编程，每个进程有单独的GIL锁，互不影响。]]></content>
      <categories>
        <category>编程基础</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>并发</tag>
        <tag>多线程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python多进程]]></title>
    <url>%2F2018%2F05%2F31%2Fpython%E5%A4%9A%E8%BF%9B%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[在Linux/Unix下，python的os.fork()可以创建子进程，原理跟C语言的fork()类似，但是该模块不支持windows。而multiprocessing模块支持跨平台。 fork()创建子进程当一个进程调用fork()函数时，系统复制一个与原进程完全相同的进程，一个进程调用fork后，系统给新进程分配资源，并把原进程的所有值都复制到新进程中，并且新进程也从原进程fork()处继续向下执行。 fork()函数执行后，会有三种返回值。 在父进程中，返回值为新创建的进程的pid，该pid大于0。 在子进程中，返回值为0。 如果出现错误，例如系统没有足够的资源创建新进程，此时返回一个负值。 12345678910111213141516171819#! /usr/bin/pythonimport osimport timeprint("Before fork process pid=%s, ppid=%s" % (os.getpid(), os.getppid()))pid = os.fork()if pid &gt; 0: print("I'm' a parent process, child process pid=%s", pid)if pid == 0: print("I am child process pid=%s, ppid=%s" % (os.getpid(), os.getppid())) time.sleep(5)else: print("I am parent process pid=%s, ppid=%s" % (os.getpid(), os.getppid())) time.sleep(5)# 下面的内容会被打印两次，一次是在父进程中，一次是在子进程中。print("After fork process pid=%s, ppid=%s" % (os.getpid(), os.getppid())) 运行结果如下 123456Before fork process pid=7322, ppid=7245I'm' a parent process, child process pid=%s 7323I am parent process pid=7322, ppid=7245I am child process pid=7323, ppid=7322After fork process pid=7322, ppid=7245After fork process pid=7323, ppid=1 Process创建简单的子进程multiprocessing模块提供了一个Process来创建子进程 12345678910111213141516#! /usr/bin/python3from multiprocessing import Processimport os# 子进程需要执行的代码def run_task(name): print('Run child process %s (%s)' % (name, os.getpid()))if __name__ == '__main__': print('Parent process %s.' % os.getpid()) p = Process(target=run_task, args=('child', )) print('child process will start.') p.start() p.join() print('child process end') 结果如下 1234Parent process 21920.child process will start.Run child process child (14856)child process end 创建子进程时，需要传入子进程执行的函数，和参数元组。 Process()创建的子进程对象使用start()方法启动子进程，join()方法使父进程处于等待状态，直到子进程结束后继续执行。 注意：父进程结束前一定要使用join()等待所有子进程结束，否则父进程结束后所有子进程将被强制关闭。 os.getpid()方法可以获取当前进程的pid 进程池例如nginx每次接收到一个连接就会创建一个子进程。 如果要创建大量的子进程，可以用进程池的方式批量创建子进程。 123456789101112131415161718192021#! /usr/bin/python3from multiprocessing import Poolimport os, time, randomdef run_task(name): print("Run task %s (%s)" % (name, os.getpid())) start = time.time() time.sleep(random.random() * 3) end = time.time() print("Task %s run %.2f seconds." % (name, (end-start)))if __name__ == '__main__': print("Parent process %s." % os.getpid()) p = Pool(5) for i in range(5): p.apply_async(run_task, args=(i, )) print("Waiting for all subprocess done.") p.close() p.join() print("All subprocess done.") 执行结果 12345678910111213Parent process 3348.Waiting for all subprocess done.Run task 0 (25452)Run task 1 (43928)Run task 2 (13760)Run task 3 (24808)Run task 4 (13480)Task 1 run 0.52 seconds.Task 3 run 1.17 seconds.Task 2 run 2.23 seconds.Task 4 run 2.44 seconds.Task 0 run 2.68 seconds.All subprocess done. 上面的Pool对象调用join()方法会等待所有子进程执行完毕，调用join()方法前必须调用close()，close()方法调用后就不能再像Pool对象种添加新的Process了。 进程间通信multiprocess提供了Queue、Pipes等多种方式来交换数据。 123456789101112131415161718192021222324from multiprocessing import Process, Queueimport os, time, randomdef write(q): print('Process to write: %s' % os.getpid()) for value in 'ABC': print('Put %s to queue...' % value) q.put(value) time.sleep(random.random())def read(q): print('Process to read: %s' % os.getpid()) while True: value = q.get(True) print('Get %s from queue.' % value)if __name__ == '__main__': q = Queue() pw = Process(target=write, args=(q, )) pr = Process(target=read, args=(q, )) pw.start() pr.start() pw.join() pr.terminate() 结果如下 12345678Process to read: 33716Process to write: 1688Put A to queue...Get A from queue.Put B to queue...Get B from queue.Put C to queue...Get C from queue. 注意：在Unix/Linux下，multiprocessing模块封装了fork()调用，使我们不需要关注fork()的细节。由于Windows没有fork调用，因此，multiprocessing需要“模拟”出fork的效果，父进程所有Python对象都必须通过pickle序列化再传到子进程去，所有，如果multiprocessing在Windows下调用失败了，要先考虑是不是pickle失败了。]]></content>
      <categories>
        <category>编程基础</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>并发</tag>
        <tag>多进程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python subprocess创建子进程]]></title>
    <url>%2F2018%2F05%2F31%2Fpython-subprocess%E5%88%9B%E5%BB%BA%E5%AD%90%E8%BF%9B%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[很多时候，我们需要调用其他子进程来处理逻辑功能，subprocess模块可以很方便的创建子进程，并控制其输出输出。 创建简单的子进程创建子进程，使用nslookup命令。 1234567#! /usr/bin/python3import subprocessprint("$ nslookup www.baidu.com")r = subprocess.call(['nslookup', 'www.baidu.com'])print('Exit code:', r) 结果如下 1234567891011$ nslookup www.baidu.com服务器: ns.sc.cninfo.netAddress: 61.139.2.69非权威应答:名称: www.a.shifen.comAddresses: 180.97.33.107 180.97.33.108Aliases: www.baidu.comExit code: 0 subprocess模块的call()方法可以运行一个命令，并且等待执行完毕。返回一个命令执行的返回值。 终端查看命令或程序执行状态可以执行完了后执行echo $?命令输出状态，linux下0为正常，非0为异常。 很多时候我们不需要将命令结果打印处理，而是需要得到返回结果并进行处理。 12345678910#! /usr/bin/python3import subprocessprint("$ nslookup www.baidu.com")# r = subprocess.call(['nslookup', 'www.baidu.com'])cmd = 'nslookup www.baidu.com'status, stdout = subprocess.getstatusoutput(cmd)print('Exit code:', status)print('execute stdout', stdout.replace('\n\n', '\n')) 结果如下 123456789$ nslookup www.baidu.comExit code: 0execute stdout 非权威应答:服务器: ns.sc.cninfo.netAddress: 61.139.2.69名称: www.a.shifen.comAddresses: 180.97.33.107 180.97.33.108Aliases: www.baidu.com subprocess的getstatusoutput命令执行了一个命令并且返回了执行状态和输出stdout。 subprocess详细方法1. 基础用法1Popen(args, bufsize=-1, executable=None, stdin=None, stdout=None, stderr=None, preexec_fn=None, close_fds=_PLATFORM_DEFAULT_CLOSE_FDS, shell=False, cwd=None, env=None, universal_newlines=False, startupinfo=None, creationflags=0, restore_signals=True, start_new_session=False, pass_fds=(), encoding=None, errors=None) args: 需要执行的命令或者执行文件的路径，一个由字符串组成的序列，列表第一个元素为可执行程序路径，其余是传入的参数。 bufsize: 控制stdin，stdout，stderr参数指定的缓冲去大小。 executable: 如果这个参数不是None，将替代参数args作为可执行程序。 stdin: 指定子进程的标准输入。 stdout：指定子进程的标准输出。 stderr：指定子进程的标准错误输出。 preexec_fn: 默认为None，否则必须是一个函数或者可调用对象，在子进程种首先执行这个函数，然后再执行子进程程序 close_fds:bool型变量，为True时在子进程执行前强制关闭所有除stdin，stdout和stderr外的文件。 shell：该程序是不是shell程序，bool变量。 cwd：代表路径的字符串，指定子进程运行的工作目录，要求该目录必须存在。 env：字典，键值都是为子进程定义环境变量的字符串。 universal_newline：bool型变量。为True时stdout和stderr以通用换行模式打开。 startupinfo/creationflags:windows有效，传递给win32的CreatProcess API调用。 Popen创建子进程后，若该python父进程结束。子进程不会结束。将成为孤儿进程，由init进程维护生命周期。 父进程结束后，使用ps -ef | grep [sub] 可以看到子进程的父进程id为1(init)。 Popen对象的属性 p.id：子进程的PID p.returncode: 表示子进程的返回状态 None： 子进程尚未结束 等于 0： 子进程正常退出 大于 0： 子进程异常退出，returncode对应域出错码 小于 0： 子进程被信号杀掉 p.stdin,p.stdout, p.stderr：子进程对应的一些出事文件，如果调用Popen()的时候对应参数是subprocess.PIPE, 则这里对应的属性是一个包裹了这个管道的file对象。 Popen对象的方法 p.poll(): 检查子进程p是否已经终止，返回p.returncode属性。 p.wait(): 等待子进程p终止，返回p.returncode属性。wait()立即阻塞父进程，直到子进程结束。 p.communicate(input=None): 和子进程p交流，将参数input(字符串)中的数据发送到子进程的stdin，同时从子进程的stdout和stderr读取数据，直到EOF。 返回值: 二元组（stdoutdata，stderrdata）分别表示从标准输出和标准错误中独处的数据。 父进程调用p.communicate()和子进程通信有下列限制： (1) 只能通过管道和子进程通信，就是说只有调用Popen()创建子进程的时候参数stdin=subprocess.PIPE, 才能通过p.communicate(input)向子进程的stdin发送数据；只有参数stdout和stderr也都为subprocess.PIPE, 才能通过p.communicate()从子进程接收数据，否则接收到的二元组中，对应的值为None。 (2) 父进程从子进程读到的数据缓存再内存中，因此communicate()不适合与子进程交换过大的数据。 注意：communicate()立即阻塞父进程，直到子进程结束。 p.send_signal(signal)： 向子进程发送信号signal； p.terminate(): 终止子进程p, 等于向子进程发送SIGTERM信号； p.kill():杀死子进程p，等于向子进程发送SIGKILL信号。 subprocess模块的其他用法 subprocess.call(args, *, stdin=None, stdout=None, stderr=None, shell=False) 父进程直接创建子进程执行程序，然后等待子进程完成 返回值：call()返回子进程的退出状态即child.returncode属性。 示例 12345678910&gt;&gt;&gt; p = subprocess.call(['ping', '-c', '2', 'www.baidu.com'])PING www.a.shifen.com (180.97.33.107) 56(84) bytes of data.64 bytes from 180.97.33.107: icmp_seq=1 ttl=52 time=30.9 ms64 bytes from 180.97.33.107: icmp_seq=2 ttl=52 time=31.5 ms--- www.a.shifen.com ping statistics ---2 packets transmitted, 2 received, 0% packet loss, time 1002msrtt min/avg/max/mdev = 30.957/31.236/31.515/0.279 ms&gt;&gt;&gt; print(p)0 subprocess.check_call(args, *, stdin=None, stdout=None, stderr=None, shell=False) 父进程直接创建子进程执行程序，然后等待子进程完成，参数类似call()方法 返回值：无论子进程是否成功，函数返回值为0。如果子进程退出状态不是0，check_call()抛出异常CalledProcessError，异常对象中包含child.returncode对应的返回码。 示例 12345678910111213141516171819&gt;&gt;&gt; p = subprocess.check_call(['ping', '-c', '2', 'www.baidu.com'])PING www.a.shifen.com (180.97.33.108) 56(84) bytes of data.64 bytes from 180.97.33.108: icmp_seq=1 ttl=52 time=39.9 ms64 bytes from 180.97.33.108: icmp_seq=2 ttl=52 time=40.4 ms--- www.a.shifen.com ping statistics ---2 packets transmitted, 2 received, 0% packet loss, time 1002msrtt min/avg/max/mdev = 39.927/40.191/40.456/0.331 ms&gt;&gt;&gt; print(p)0&gt;&gt;&gt; p = subprocess.check_call(['ping', '-c', '2', 'www.123@#$fs.com'])ping: unknown host www.123@#$fs.comTraceback (most recent call last): File "&lt;stdin&gt;", line 1, in &lt;module&gt; File "/usr/local/lib/python3.6/subprocess.py", line 291, in check_call raise CalledProcessError(retcode, cmd)subprocess.CalledProcessError: Command '['ping', '-c', '2', 'www.123@#$fs.com']' returnednon-zero exit status 2.&gt;&gt;&gt; print(p)0 subprocess.check_output(args, *, stdin=None, stderr=None, shell=False, universal_newlines=False) 父进程直接创建子进程执行程序，以字符串形式返回子进程输出。 返回值：字符串形式的子进程输出结果，如果子进程退出状态不为0，则抛出异常CalledProcessError，异常对象中包含了child.returncode对应的返回码。 123456789101112&gt;&gt;&gt; p = subprocess.check_output(['ping', '-c', '2', 'www.baidu.com'])&gt;&gt;&gt; print(p)b'PING www.a.shifen.com (180.97.33.108) 56(84) bytes of data.\n64 bytes from 180.97.33.108: icmp_seq=1 ttl=52 time=39.3 ms\n64 bytes from 180.97.33.108: icmp_seq=2 ttl=52 time=40.1 ms\n\n--- www.a.shifen.com ping statistics ---\n2 packets transmitted, 2 received, 0% packet loss, time 1002ms\nrtt min/avg/max/mdev = 39.396/39.780/40.164/0.384 ms\n'&gt;&gt;&gt; p = subprocess.check_output(['ping', '-c', '2', 'www.ba@#$%idu.com'])ping: unknown host www.ba@#$%idu.comTraceback (most recent call last): File "&lt;stdin&gt;", line 1, in &lt;module&gt; File "/usr/local/lib/python3.6/subprocess.py", line 336, in check_output **kwargs).stdout File "/usr/local/lib/python3.6/subprocess.py", line 418, in run output=stdout, stderr=stderr)subprocess.CalledProcessError: Command '['ping', '-c', '2', 'www.ba@#$%idu.com']' returned non-zero exit status 2. subprocess.getstatusoutput(cmd) 执行cmd命令并返回结果 返回值：二元组(returncode, stdout)返回子进程退出状态及输出。 示例 123&gt;&gt;&gt; status, stdout = subprocess.getstatusoutput('echo "123"')&gt;&gt;&gt; print(status, stdout)0 123 subprocess.PIPE 调用本模块提供的若干函数时，作为std*参数的值，为标准流文件打开一个管道。 123456789&gt;&gt;&gt; child1 = subprocess.Popen(['ls', '-l'], stdout=subprocess.PIPE)&gt;&gt;&gt; child2 = subprocess.Popen(['wc', '-l'], stdin=child1.stdout, stdout=subprocess.PIPE)&gt;&gt;&gt; out = child2.communicate()&gt;&gt;&gt; child1.wait()0&gt;&gt;&gt; child2.wait()0&gt;&gt;&gt; print(out)(b'13\n', None) 注意： 由于call()、check_all()和check_output()默认等待子进程完成，如果参数stderr和stdout设置为subprocess.PIPE，子进程产生大量的输出数据如果造成管道堵塞，父进程再等待子进程完成可能造成死锁。 subprocess模块定义的异常1exception subprocess.CalledProcessError (1) 什么时候可能抛出该异常：调用check_call()或check_output()，子进程的退出状态不为0时。 (2) 该异常包含以下信息： returncode: 子进程退出状态。 cmd: 创建子进程时指定的指令。 output: 如果时调用check_output()时抛出的该异常，这里包含子进程的输出，否则该属性为None。 总结subprocess缺点：父子进程通信方法只有管道；同事创建的子进程专门用来执行外部的程序或命令。]]></content>
      <categories>
        <category>编程基础</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>subprocess</tag>
        <tag>子进程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python 装饰器]]></title>
    <url>%2F2018%2F05%2F25%2Fpython-%E8%A3%85%E9%A5%B0%E5%99%A8%2F</url>
    <content type="text"><![CDATA[在开发过程中，经常会遇到需要更改别人代码的情况。直接修改函数内部代码容易引起逻辑混乱，使用装饰器能够很好的避免这种问题。 由于python的函数也是一个对象，可以赋值给变量，通过变量调用函数。 12345678910#! /usr/bin/python3.6def haha(): print('in the haha')a = hahaprint(haha)print(a)a()print(a.__name__) 结果如下 1234&lt;function haha at 0x7f666fb5ce18&gt;&lt;function haha at 0x7f666fb5ce18&gt;in the hahahaha 无参装饰器下面例子完成了在调用add函数时打印函数名和行数。可以用做简单的日志输出。 1234567891011121314151617#!/usr/bin/python3.6import sysdef log(func): def wrapper(*args, **kwargs): print('%s is runing, line[%s]' % (func.__name__, sys._getframe().f_lineno)) return func(*args, **kwargs) return wrapper@logdef add(num1, num2): return num1 + num2number1 = add(1, 2)print(number1)print('func:', log(add)) 结果如下 123add is runing, line[9]3&lt;function log.&lt;locals&gt;.wrapper at 0x02F9BA98&gt; 可以看到log1返回的函数是wrapper而不是add， 我们可以调用functools.wraps(func)装饰器来使wrapper返回的装饰器名称为add。 1234567import functools...@functools.wraps(func)def wrapper(*args, **kwargs): # func conectent ...... 带参装饰器123456789101112131415161718192021222324#!/usr/bin/python3.6import sysimport functoolsdef log(logfile): def decorator(func): @functools.wraps(func) def wrapper(*args, **kwargs): print('logfile: %s, %s is runing, line[%s]' % (logfile, func.__name__, sys._getframe().f_lineno)) return func(*args, **kwargs) return wrapper return decorator# 注意该logfile需要定义在添加装饰器的前面logfile = '/var/log/1.log'@log(logfile)def add(num1, num2): return num1 + num2number1 = add(1, 2)print(number1)print('func:', log(add)) 结果如下 123logfile: /var/log/1.log, add is runing, line[10]3func: &lt;function log.&lt;locals&gt;.decorator at 0x03AE4978&gt; 总结在编写程序时在流程函数或者类前加上日志装饰器会很容易的判断程序运行流程。 装饰器原理就是一个拦截器，在程序执行到函数时，遇到装饰器会先执行装饰器函数，然后执行装饰器返回的函数。 注意：由于python的解释原理，在执行代码前定义的函数会被加载，此时的装饰器就已经被调用并且返回了函数，所以装饰器的参数必须在该装饰器函数被解释之前就定义。]]></content>
      <categories>
        <category>编程基础</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>装饰器</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python3 高级内置函数]]></title>
    <url>%2F2018%2F05%2F23%2Fpython3-%E9%AB%98%E7%BA%A7%E5%86%85%E7%BD%AE%E5%87%BD%E6%95%B0%2F</url>
    <content type="text"><![CDATA[python使用lambda表达式来支持匿名函数 python内置函数中比较常用的内置函数 filter/map/reduce/sorted/zip lambda匿名函数python提供了匿名函数。此类函数不需要提供函数名，不用担心函数名冲突。 python使用lambda关键字表示匿名函数，匿名函数只能有一个表达式，不用写return。返回值就是该表达式的结果。 匿名函数也是一个函数对象，可以把匿名函数赋给一个变量，再用该变量来调用函数 12345&gt;&gt;&gt; a = lambda x: x * 2&gt;&gt;&gt; a&lt;function &lt;lambda&gt; at 0x7fb1839a4e18&gt;&gt;&gt;&gt; a(3)6 可以看到lambda表达式将匿名函数对象赋值给了a，并且可以直接调用a。 filter 用法: filter(func, obj) 12345678910111213141516171819202122class filter(object) | filter(function or None, iterable) --&gt; filter object | | Return an iterator yielding those items of iterable for which function(item) | is true. If function is None, return the items that are true. | | Methods defined here: | | __getattribute__(self, name, /) | Return getattr(self, name). | | __iter__(self, /) | Implement iter(self). | | __new__(*args, **kwargs) from builtins.type | Create and return a new object. See help(type) for accurate signature. | | __next__(self, /) | Implement next(self). | | __reduce__(...) | Return state information for pickling. 用途: 过滤与func()不匹配的值，可以看到该类属于一个迭代器类，调用一个bool函数func来迭代seq中的元素，返回值bool_seq是一个True的迭代器 第一个参数：为过滤函数或None 第二个参数：一个可迭代的对象 实例 删除偶数 12345def is_odd(n): return n % 2 == 1list(filter(is_odd, range(8)))# 结果# [1, 3, 5, 7] ​ 过滤空值 123list(filter(None, [-1, 0, 2, '', &#123;&#125;, (), []]))# 结果# [-1, 2] ​ 筛选素数 12345678910111213141516171819202122def odd_iter(): n = 1 while True: n += 2 yield ndef not_divisible(n): return lambda x: x % n &gt; 0def primes(): yield 2 it = odd_iter() while True: n = next(it) yield n it = filter(not_divisible(n), it)# 打印100以内的素数ll = []for n in primes(): if n &lt; 100: ll.append(n) else: breakprint(ll) 结果如下 1[2, 3, 5, 7, 11, 13, 17, 19, 23, 29, 31, 37, 41, 43, 47, 53, 59, 61, 67, 71, 73, 79, 83, 89, 97] map 用法 map(func, obj) 第一个函数为映射函数，第二个obj为可迭代对象。返回值为一个map对象 实例 12&gt;&gt;&gt; list(map(lambda x: x*2, range(10)))[0, 2, 4, 6, 8, 10, 12, 14, 16, 18] reduce 用法 reduce(func, obj) 第一个函数必须接收两个参数，第二个函数是一个可迭代对象。 reduce函数回将obj的每个元素调用func函数，并把结果继续和下个元素做累积计算。 注意：python3中reduce被移到了functools库中，使用需要先引用该库 123import functools&gt;&gt;&gt; functools.reduce(lambda x, y: x*2+y, range(10))1013 sorted排序算法是比较常用的算法。 sorted(iterable, /, *, key=None, reverse=False) sorted可以接收一个key作为自定义函数来排序， reverse为False则从小到大排序，reverse为True则从大到小排序。 1234&gt;&gt;&gt; sorted([13, -54, 3, -543, 2, 34])[-543, -54, 2, 3, 13, 34]&gt;&gt;&gt; sorted([13, -54, 3, -543, 2, 34], key=abs)[2, 3, 13, 34, -54, -543] zipzip()将多个可迭代对象压缩为一个tuple并返回一个可迭代对象。 参数可传入多个可迭代对象。若传入的多个可迭代对象长度不等，则返回list长度等于参数中最短的可迭代对象长度。 12&gt;&gt;&gt; list(zip(range(5), range(1, 30, 3), range(4, 40, 2)))[(0, 1, 4), (1, 4, 6), (2, 7, 8), (3, 10, 10), (4, 13, 12)] 这个函数用来很轻松的实现矩阵转换 123456789a = list(range(11, 15))b = list(range(21, 25))c = list(range(31, 35))d = [a, b, c]for i in d: print(i)dz = zip(*d)for i in dz: print(i) 结果如下 1234567[11, 12, 13, 14][21, 22, 23, 24][31, 32, 33, 34](11, 21, 31)(12, 22, 32)(13, 23, 33)(14, 24, 34)]]></content>
      <categories>
        <category>编程基础</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>内置函数</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python3 常用内置函数]]></title>
    <url>%2F2018%2F05%2F22%2Fpython-%E5%B8%B8%E7%94%A8%E5%86%85%E7%BD%AE%E5%87%BD%E6%95%B0%2F</url>
    <content type="text"><![CDATA[python之所以轻巧灵活优雅，速度块时因为python内置了大量使用C实现的函数。使用内置函数有下面的优点。 速度快，使用内置函数，比普通的PYTHON实现，速度要快一倍左右。相当于C/C++的速度 代码简洁 数学相关 abs(x)函数 abs(x)函数返回数字x的绝对值，如果x为复数，返回值为该复数的模 12345678&gt;&gt;&gt; print(abs(-100))100&gt;&gt;&gt; abs(-100)100&gt;&gt;&gt; abs(-101.32)101.32&gt;&gt;&gt; abs(1+2j)2.23606797749979 divmod(x, y) divmod(x, y)函数完成除法运算，返回商和余数。除数不能为0 12345678&gt;&gt;&gt; divmod(10, 3)(3, 1)&gt;&gt;&gt; divmod(9, 3)(3, 0)&gt;&gt;&gt; divmod(5, 0)Traceback (most recent call last): File "&lt;stdin&gt;", line 1, in &lt;module&gt;ZeroDivisionError: integer division or modulo by zero pow(x, y, z=None) pow()函数以x为底，y为指数的幂。如果给出z值，改函数就计算x的y次幂值被z取模的值 1234&gt;&gt;&gt; pow(2, 3)8&gt;&gt;&gt; pow(2, 3, 3)2 round(x[, n]) round()函数返回浮点数x的四舍五入值，如给出n值，则代表四舍五入后精确到小数点后几位 1234&gt;&gt;&gt; round(3.3333, 2)3.33&gt;&gt;&gt; round(5.78)6 max(x[, y, z…]) / min(x[, y, z…]) max()函数返回给定参数的最大值，参数可以为list序列。 min()函数返回给定参数的最小值，用法参数同max()函数 若参数为元组，则跟C语言字符串比较类似，从第一个开始比较，直到找到大的值则返回该元组。 12345678&gt;&gt;&gt; max([1, 2, 3, 5, 9, 22])22&gt;&gt;&gt; max(3, 2, 5, 1)5&gt;&gt;&gt; max((1, 2, 3), (2, 1, 3))(2, 1, 3)&gt;&gt;&gt; max((1, 2, 3), (1, 9, 3))(1, 9, 3) sum(iterable, start=0) sum()函数第一参数为一个迭代器，第二个参数不传默认初始和为0 1234&gt;&gt;&gt; sum([5, 2, 34])41&gt;&gt;&gt; sum([5, 2, 34], -1)40 序列相关 len(object) -&gt; integer len()返回字符串和序列或者元组的长度 123456&gt;&gt;&gt; len('aaa')3&gt;&gt;&gt; len([1, 2, 3])3&gt;&gt;&gt; len((12, 32))2 range([lower,]stop[,step]) python2: range()函数可以按照参数生成连续的有序整数列表。 python3: range()函数生成一个range(迭代器)的对象，只在需要时才计算列表只。当列表很大时，可以节约内-存。python2的xrange等同于python3的range，python3没有xrange。 下面是python3的range()结果 12&gt;&gt;&gt; range(10)range(0, 10) 对象及类型 callable(object) callable()函数用域测试对象是否可以调用，如果可以则返回1(真); 否则返回0(假)。可调用对象包括函数、方法、代码对象、类和已定义了的调用方法的类实例。 1234&gt;&gt;&gt; callable(chr)True&gt;&gt;&gt; callable('123')False 比较函数 python2: 使用cmp(x, y)来比较两个对象 cmp()函数比较x和y两个对象，并根据比较结果返回一个整数，如果x&gt;y， 则返回1，如果x==y则返回0，如果x&lt;y，则返回-1。 python3: 使用operator模块中的比较函数来替代cmp，都有lt(a, b); le(a, b); eq(a, b); ne(a, b); ge(a, b); gt(a, b)。 lt：小于 le: 小于等于 eq: 等于 ne: 不等于 gt: 大于 ge: 大于等于 12345678910111213&gt;&gt;&gt; from operator import *&gt;&gt;&gt; lt(1, 2)True&gt;&gt;&gt; le(1, 2)True&gt;&gt;&gt; eq(1, 2)False&gt;&gt;&gt; ne(1, 2)True&gt;&gt;&gt; gt(1, 2)False&gt;&gt;&gt; ge(1, 2)False isinstance(object, class-or-tuple) 该函数用来判断object对象是否属于某种类型 12345678&gt;&gt;&gt; isinstance('123', str)True&gt;&gt;&gt; isinstance(11, int)True&gt;&gt;&gt; isinstance(range(10), int)False&gt;&gt;&gt; isinstance(range(10), range)True type(obj) type()函数可以返回该对象的数据类型 123456&gt;&gt;&gt; type('123')&lt;class 'str'&gt;&gt;&gt;&gt; type(11)&lt;class 'int'&gt;&gt;&gt;&gt; type(range(10))&lt;class 'range'&gt; 类型转换 chr(i) chr()函数返回ASCII码对应的字符串 1234&gt;&gt;&gt; chr(64)'@'&gt;&gt;&gt; chr(65)+chr(89)'AY' ord(x) ord()函数返回一个字符串参数的ASCII码或Unicode值。 1234&gt;&gt;&gt; ord('a')97&gt;&gt;&gt; ord(u'a')97 str(obj) str()函数把对象转换成可打印字符串。python3的str为unicode编码 123456&gt;&gt;&gt; str('a')'a'&gt;&gt;&gt; str(3+2j)'(3+2j)'&gt;&gt;&gt; str(3+10)'13' 进制转换 int(x[, base]) int()函数把数字和字符串转换成一个整数，base为可选的基数，默认为10。 python3没有long类型了。int即是long 12345678&gt;&gt;&gt; int(3)3&gt;&gt;&gt; int(5.5)5&gt;&gt;&gt; int('123')123&gt;&gt;&gt; int('14', 15)19 hex(x) hex()函数可以把整数转换为十六进制字符串。 123456&gt;&gt;&gt; hex(15)'0xf'&gt;&gt;&gt; hex(133)'0x85'&gt;&gt;&gt; type(hex(15))&lt;class 'str'&gt; oct(x) oct()函数可以把给出的整数转换为八进制数。 1234&gt;&gt;&gt; oct(125)'0o175'&gt;&gt;&gt; oct(22)'0o26' complex(real[,imaginary]) complex()函数可以把字符串或数字转换为复数。 123456&gt;&gt;&gt; complex(1+2j)(1+2j)&gt;&gt;&gt; complex(2)(2+0j)&gt;&gt;&gt; complex(2, 1)(2+1j) 数据结构 tuple(x) tuple()函数把序列对象转换为tuple元组。 1234&gt;&gt;&gt; tuple('hello')('h', 'e', 'l', 'l', 'o')&gt;&gt;&gt; tuple(range(5))(0, 1, 2, 3, 4) list(x) list()函数可将序列对象转换成列表。 123456&gt;&gt;&gt; list('afdsaf')['a', 'f', 'd', 's', 'a', 'f']&gt;&gt;&gt; list(range(5))[0, 1, 2, 3, 4]&gt;&gt;&gt; list((1, 2, 3,))[1, 2, 3]]]></content>
      <categories>
        <category>编程基础</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>内置函数</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[linux nmcli网络配置]]></title>
    <url>%2F2018%2F05%2F22%2Flinux-nmcli%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[以前修改网络都是vi /etc/sysconfig/network-scripts/ifcfg-eth0这样直接在文件中修改，经常会忘掉字段名和漏写或者写错导致网络无法启动。 现在使用nmcli命令可以更加安全高效的配置网络。 nmcli用法下面先来看看nmcli命令语法 12345678910111213141516171819202122[centos@localhost ~]$ nmcli helpUsage: nmcli [OPTIONS] OBJECT &#123; COMMAND | help &#125;OPTIONS -t[erse] terse output -p[retty] pretty output -m[ode] tabular|multiline output mode -f[ields] &lt;field1,field2,...&gt;|all|common specify fields to output -e[scape] yes|no escape columns separators in values -n[ocheck] don't check nmcli and NetworkManager versions -a[sk] ask for missing parameters -w[ait] &lt;seconds&gt; set timeout waiting for finishing operations -v[ersion] show program version -h[elp] print this helpOBJECT g[eneral] NetworkManager's general status and operations n[etworking] overall networking control r[adio] NetworkManager radio switches c[onnection] NetworkManager's connections d[evice] devices managed by NetworkManager a[gent] NetworkManager secret agent or polkit agent OPTIONS和COMMAND可以用全称也可以用简称，简称可以为全称的首字母或者前三个字母。 nmcli支持TAB补全命令 OPTIONS中常用的就是connection、device。 connection：配置网络连接，逻辑配置 device：配置网络接口，物理配置 多个connection可以使用同一个device，但是同一时间只能启动一个。 查看配置查看网络连接配置 12nmcli connection show #查看当前所有连接,-a显示可用的连接nmcli connection show eth0 #查看eth0配置 123456[centos@localhost ~]$ nmcli c showNAME UUID TYPE DEVICEWired connection 2 d4233d32-134c-4088-9b38-9a3f9ad13550 802-3-ethernet --Wired connection 1 570c114f-6835-42b9-9878-40bb2d514709 802-3-ethernet eno33554984eno16777736 8c09a582-e91d-4c60-8792-16c555fdac8d 802-3-ethernet eno16777736virbr0 4d94df18-b2cb-4249-9727-fd0a1fa9966a bridge virbr0 查看网络接口配置 12nmcli device status #查看当前网络接口状态nmcli device show eno16777736 #查看eno16777736接口状态 1234567[centos@localhost ~]$ nmcli device statusDEVICE TYPE STATE CONNECTIONvirbr0 bridge connected virbr0eno16777736 ethernet connected eno16777736eno33554984 ethernet connected Wired connection 1virbr0-nic ethernet unavailable --lo loopback unmanaged -- 添加删除网络连接 添加删除网络配置连接命令 1234# 添加nmcli con add con-name eth1 ifname eth1 type ethernet ip4 10.0.3.120/24 gw4 10.0.3.2# 删除nmcli c delete eth1 添加一个网络连接配置 1nmcli con add con-name eth1 ifname eth1 type ethernet con-name后跟的eth1为新建的配置名，ifname后跟网络接口名称，type为ethernet表示以太网，ipve设置为默认dhcp。 创建连接后会在/etc/sysconfig/network-scripts/下新建一个ifcfg-eth1的配置文件。手动更改该文件和使用nmcli命令修改是同步生效的。 重启网络配置 123nmcli con reload eth1 # 重新eth1加载配置,修改配置后需要重新加载配置重启才能生效nmcli con down eth1 # 断开该eth1网络连接nmcli con up eth1 # 打开该eth1网络连接 删除网络配置 1nmcli c delete eth1 注意：如果对应的device为connect状态，直接删除连接，可能会出创建一个以Wired connection x命名的连接，且是–inactive状态。为了避免这种情况。建议先使用nmcli d disconnect {devx}断开该连接，然后再删除对应的connection连接。 另外一种方式修改/etc/NetworkManager/NetworkManager.conf配置文件。最好在/etc/NetworkManager/conf.d/下新建一个配置文件，不要改动原配置文件。 需要添加的配置如下。 12[main]no-auto-default=* 创建静态ip 1nmcli con add con-name eth1 ifname eth1 type ethernet ipv4.addresses 10.0.3.11/24 ipv4.gateway 10.0.3.1 ipv4.dns 114.114.114.114 autoconnect yes 其中ipv4.addresses后跟的是ipv4地址和掩码，ipv4.gateway后跟的是防火墙地址，autoconnect表示开机自启。 可以设置哪些字段可以使用nmcli c s ethx命令查看。 修改网络连接修改网络连接命令 1nmcli con modify eth1 +ipv4.address 2.2.2.2/24 也可以直接进入交互式模式进行修改 1nmcli con edit eth1 # 可以进入交互式模式 交互模式下使用print可以打印当前网络配置的所有配置情况，也可以打印单独的某个配置。 在交互模式下使用tab可以看到有下列选项。 123nmcli&gt; activate describe help print remove setback goto nmcli quit save verify 常用的有print打印信息，set设置值，quit离开前一定要使用save保存。 也可以使用help查看交互式命令的详细情况 12345678910111213141516nmcli&gt; help---------------------------------------------------------------------------------[ Main menu ]---goto [&lt;setting&gt; | &lt;prop&gt;] :: go to a setting or propertyremove &lt;setting&gt;[.&lt;prop&gt;] | &lt;prop&gt; :: remove setting or reset property valueset [&lt;setting&gt;.&lt;prop&gt; &lt;value&gt;] :: set property valuedescribe [&lt;setting&gt;.&lt;prop&gt;] :: describe propertyprint [all | &lt;setting&gt;[.&lt;prop&gt;]] :: print the connectionverify [all | fix] :: verify the connectionsave [persistent|temporary] :: save the connectionactivate [&lt;ifname&gt;] [/&lt;ap&gt;|&lt;nsp&gt;] :: activate the connectionback :: go one level up (back)help/? [&lt;command&gt;] :: print this helpnmcli &lt;conf-option&gt; &lt;value&gt; :: nmcli configurationquit :: exit nmcli------------------------------------------------------------------------------ 网卡聚合绑定 bond网卡bond是通过把多张网卡绑定为一个逻辑网卡，实现本地网卡的冗余，带宽和负载均衡作用。是一种应用部署的常见网络配置技术。 bond技术模式种类 Mode=0(balance-rr)表示负载均衡round-robin,和交换机的聚合强制不协商方式配合。 Mode=1(active-backup)表示主备模式，只有一块网卡是active，另一块是备用standby,这时候如果交换机配得是捆绑则不能工作。 Mode=2(balance-xor)表示XOR hash负载均衡模式，和交换机得聚合强制不协商模式配合(需要xmit_hash_policy) Mode=3(broadcast)表示所有包从所有interface发出，这个不均衡，只有冗余机制，和交换机得聚合强制不协商方式配合。 Mode=4(802.3ad)表示支持802.3ad协议，和交换机的聚合LACP方式配合(需要xmit_hash_policy) Mode=5(balance-tlb)是根据每个slave的负载情况选择slave进行发送，接受时使用当前轮到的slave Mode=6(balance-alb)在5的tlb基础上增加了rlb bond创建方法 12345678910111213# 创建一个bond[root@localhost centos]# nmcli conn add con-name bond0 type bond ifname bond0 mode active-backupConnection 'bond0' (c14b3aeb-4307-4161-af6a-767a6ddee01f) successfully added.# 查看connection[root@localhost centos]# nmcli c showNAME UUID TYPE DEVICEeth2 07aa799c-651b-41ab-a7ba-2452b16655f7 802-3-ethernet --bond0 c14b3aeb-4307-4161-af6a-767a6ddee01f bond bond0eth1 aa44ca20-64d0-4aba-9ba1-ead861f5eba1 802-3-ethernet --virbr0 4d94df18-b2cb-4249-9727-fd0a1fa9966a bridge virbr0Wired connection 2 d4233d32-134c-4088-9b38-9a3f9ad13550 802-3-ethernet --Wired connection 1 570c114f-6835-42b9-9878-40bb2d514709 802-3-ethernet eno33554984eno16777736 8c09a582-e91d-4c60-8792-16c555fdac8d 802-3-ethernet eno16777736 现在将eth1和eth2添加到bond0中 12nmcli c add type bond-slave ifname eth1 master bond0nmcli c add type bond-slave ifname eth2 master bond0 然后会看到多了两个连接bond-slave-eth1和bond-slave-eth2 1234567891011[root@localhost centos]# nmcli c showNAME UUID TYPE DEVICEeth2 07aa799c-651b-41ab-a7ba-2452b16655f7 802-3-ethernet --bond0 c14b3aeb-4307-4161-af6a-767a6ddee01f bond bond0bond-slave-eth2 f6d234d3-976f-4d12-b9ab-230494893d2d 802-3-ethernet --eth1 aa44ca20-64d0-4aba-9ba1-ead861f5eba1 802-3-ethernet --virbr0 4d94df18-b2cb-4249-9727-fd0a1fa9966a bridge virbr0Wired connection 2 d4233d32-134c-4088-9b38-9a3f9ad13550 802-3-ethernet --Wired connection 1 570c114f-6835-42b9-9878-40bb2d514709 802-3-ethernet eno33554984eno16777736 8c09a582-e91d-4c60-8792-16c555fdac8d 802-3-ethernet eno16777736bond-slave-eth1 7e817e1a-717d-497b-b7dc-1012e093e7d0 802-3-ethernet -- 启动这两个连接即可。 参考文档 GNOME NetworkManager nmcli命令]]></content>
      <categories>
        <category>折腾笔记</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>nmcli</tag>
        <tag>网络配置</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[linux sudo配置权限]]></title>
    <url>%2F2018%2F05%2F21%2Flinux-sudo%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[在程序执行的时候，或多或少会需要调用系统命令，而这些命令有些需要sudo权限，为了让程序有执行权限又不让执行程序的用户拥有所有命令的sudo权限。 例如给admin用户关机权限 将配置加入/etc/sudoers在/etc/sudoers文件末尾添加#includedir /your/sudoers.d/，然后在/your/sudoers.d/目录下创建权限配置文件 注意，#includer的#不是注释 使用visudo -f power.sudoer.conf 123admin ALL=(:power) NOPASSWD: /usr/bin/sudo%power ALL=(root) NOPASSWD: /usr/sbin/shutdown -h now%power ALL=(root) NOPASSWD: /usr/sbin/shutdown -r now 使用visudo命令编辑文件保存退出时会检测命令格式。 将用户添加到特定组中。将admin用户添加到power组里。 使用cat /etc/passwd查看组是否有power组 123cat /etc/group # 查看用户组groupadd power # 若没有查找到该组则新建组usermod -a -G power admin # 将添加到该组，记得使用-a，否则将会清空admin原有的组 下面重要的事说三遍 该文件一定要是linux下的文件。不要在windows下编辑在拷贝过来，windows下的文件是dos文件。 该文件一定要是linux下的文件。不要在windows下编辑在拷贝过来，windows下的文件是dos文件。 该文件一定要是linux下的文件。不要在windows下编辑在拷贝过来，windows下的文件是dos文件。 将dos文件转换为linux文件。 12yum install dos2unixdos2unix power.sudoer.conf sudo配置文件格式解析12admin ALL=(:power) NOPASSWD: /usr/bin/sudo%power ALL=(root) NOPASSWD: /usr/sbin/shutdown -h now 第一栏为适用对象：用户或组。组对象使用%开头，上例admin为用户名，power为用户组。 第二栏为该规则的适用主机：填写对应主机名，ALL表示所有主机都生效。 第三栏括号内的值规定用户以什么样的身份来执行命令：上例的root即为使用root帐号身份来执行，:power表示使用power用户组身份来执行。 第四栏是使用英文半角逗号作为分隔符的命令表：NOPASSWD表示该命令不需要输出密码。 注意：命令表里的命令需要使用绝对路径 实例 配置m_network组内的sysadm和nginx用户可以执行nmcli命令用以配置管理网络。 12345sysadm ALL=(:m_network) NOPASSWD: /usr/bin/sudo, NOPASSWD: SETENV: /usr/bin/sudoeditnginx ALL=(:m_network) NOPASSWD: /usr/bin/sudo, NOPASSWD: SETENV: /usr/bin/sudoedit%m_network ALL=(root) NOPASSWD: /usr/bin/nmcli%m_network ALL=(root) NOPASSWD: sudoedit /etc/resolv.conf 上面配置可以让m_network组里的sysadm用户拥有/usr/bin/sudo执行权限且不要密码，让m_network组的所有用户可以执行/usr/bin/nmcli和sudoedit /etc/resolv.conf命令。 SETENV: /usr/bin/sudoedit用来编辑器 让m_systemctl组内用户可以以root身份免密执行systemctl重启nginx和php-fpm服务 12345678910sysadm ALL=(:m_systemctl) NOPASSWD: /usr/bin/sudonginx ALL=(:m_systemctl) NOPASSWD: /usr/bin/sudo %m_systemctl ALL=(root) NOPASSWD: /usr/bin/systemctl restart nginx.service%m_systemctl ALL=(root) NOPASSWD: /usr/bin/systemctl start nginx.service%m_systemctl ALL=(root) NOPASSWD: /usr/bin/systemctl stop nginx.service%m_systemctl ALL=(root) NOPASSWD: /usr/bin/systemctl restart php-fpm.service%m_systemctl ALL=(root) NOPASSWD: /usr/bin/systemctl start php-fpm.servic%m_systemctl ALL=(root) NOPASSWD: /usr/bin/systemctl stop php-fpm.servic 直接使用sysadm用户执行命令 12/usr/bin/sudo -n -g m_systemctl /usr/bin/sudo /usr/bin/systemctl restart nginx... 配置权限必须得配置详细到命令，命令使用绝对路径。 将某用户配置为可以执行所有sudo操作 1sysadm ALL=(root) NOPASSWD:ALL]]></content>
      <categories>
        <category>折腾笔记</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>sudo</tag>
        <tag>权限</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[centos7安装python3环境]]></title>
    <url>%2F2018%2F05%2F19%2Fcentos7%E5%AE%89%E8%A3%85python3%E7%8E%AF%E5%A2%83%2F</url>
    <content type="text"><![CDATA[centos7上默认的是python版本是2.7的，而python到2020年将不再对2进行维护，只做商业维护。大量的库已经从2迁移到了3，如果使用python开发持续性的可维护工具，建议使用python3。 下面来介绍下在centos7环境下如何安装python3环境。 0x01 使用yum安装安装EPEL和IUS软件源 12yum install epel-releaseyum install https://centos7.iuscommunity.org/ius-release.rpm 安装python3.6 1yum install python36u 安装pip3,安装后会有pip3.6和easy_install-3.6两个工具可以使用 1yum install python36u-pip 安装python和pip后可以创建软连接，方便使用 12ln -s /usr/bin/python3.6 /bin/python3ln -s /usr/bin/pip3.6 /usr/bin/pip3 安装之后路径 python程序目录/usr/lib(64)/python3.6 可运行程序/usr/bin/python3.6 库文件夹/usr/lib(64)/python3.6/ 0x02 使用源码安装到下载www.python.org下载源码包 12345wget https://www.python.org/ftp/python/3.6.5/Python-3.6.5.tar.xztar -zJf Python-3.6.5.tar.xzcd Python3.6.5sudo ./configuresudo make &amp; sudo make install 源码安装后路径， python程序安装在了/usr/local/python3.6/中 可运行程序为/usr/bin/python3.6 库文件夹/usr/local/lib/ 0x03 调试环境 如果需要python调试环境，可以使用下面步骤安装，生产环境建议使用大量日志。方便排错，因为有些bug不太容易复现。 使用pycharm进行远程调试 安装pydevd 123pip3.6 install pydevd# 安装pycharm的egg调试包easy_install-3.6 --install-dir /usr/lib64/python3.6/site-packages pycharm-debug-py3k.egg 在需要调试的脚本开头添加 12import pydevdpydevd.settrace('pycharm_host', port=pycharm_port_num, stdoutToServer=True, stderrToServer=True) 在pycharm的edit configured添加一个python remote debug。 local host name设置为localhost port设置为pycharm_port_num 使用pdb调试 12345678910# 开启调试python -m pdb xxx.py# 调试方法b # 查看断点b num #在第num行处下断点b xxx.py:num #在xxx.py文件的第num行下断点，xxx.py文件支持相对路径切换到其他目录r # 执行到下个断点处p var # 打印var的值n # 单步执行l # 查看当前停止行]]></content>
      <categories>
        <category>折腾笔记</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>python3</tag>
        <tag>python环境</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python可变对象和不可变对象]]></title>
    <url>%2F2018%2F05%2F18%2Fpython-%E5%8F%AF%E5%8F%98%E5%AF%B9%E8%B1%A1%E5%92%8C%E4%B8%8D%E5%8F%AF%E5%8F%98%E5%AF%B9%E8%B1%A1%2F</url>
    <content type="text"><![CDATA[python的数据类型分为可变对象(mutable)和不可变对象(immutable)。 可变对象的赋值是一个浅拷贝操作，不可变对象的赋值是一个深拷贝操作。 可变对象可变对象：list,dict 例如 123456789101112131415161718#! /usr/bin/python3def add_to(num, target=[]): target.append(num) return targeta = add_to(1)print(a)a.append(4)print(a)b = add_to(2)print(b)c = add_to(3)print(c)print('-'*20)print(a)print(b)print(c) 结果如下 12345678[1][1, 4][1, 4, 2][1, 4, 2, 3]--------------------[1, 4, 2, 3][1, 4, 2, 3][1, 4, 2, 3] 可以看到结果的a，b，c三个对象值和内存地址都是一样的。 ​ 在Python中当函数被定义时，默认参数只会运算一次，而不是每次被调用时都会重新运算。你应该永远不要定义可变类型的默认参数，除非你知道你正在做什么。 ​ 所以target这个可变参数被进行了几次浅拷贝。导致以个变量的值改变会同时改变其他变量的值。类似与C语言的多个指针同时指向一个地址。 上面函数可以这样定义。 12345def add_to(element, target=None): if target is None: target = [] target.append(element) return target python的可变对象有：字典dict，数组list 不可变对象不可变对象: string, int, float, tuple 将上面的target从[]改为数字 1234567891011121314151617181920def add_to(num, target=10): target += 1 return targeta = add_to(1)print(a)a += 4print(a)b = add_to(2)print(b)c = add_to(3)print(c)print('-'*20)print(a, id(a))print(b, id(b))print(c, id(c))b += 5c += 10print(b, id(b))print(c, id(c)) 结果如下 1234567891011151111--------------------15 49547464011 49547457611 49547457616 49547465621 495474736 可以发现数字的赋值进行的深拷贝。说明数字是不可变对象。 注意：第14行和第15行输出可以看到a和b的内存地址相同。这是由于python的常用数字常驻内存，这是为了加快运行速度所作的优化。]]></content>
      <categories>
        <category>编程基础</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>可变对象</tag>
        <tag>不可变对象</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python判断IP地址合法性]]></title>
    <url>%2F2018%2F05%2F18%2Fpython-ip%E5%90%88%E6%B3%95%E6%80%A7%E6%A0%A1%E9%AA%8C%2F</url>
    <content type="text"><![CDATA[开发的一个必要技能是对所有参数进行合法性校验。 下面便来看下在网络编程中对ip地址的合法性校验。 0x01 正则表达式校验正则匹配式如下,^和$分别是对字符串开头和结尾的校验 匹配ipv4如下 1^(1\d&#123;2&#125;|2[0-4]\d|25[0-5]|[1-9]\d|[1-9])\.(1\d&#123;2&#125;|2[0-4]\d|25[0-5]|[1-9]\d|\d)\.(1\d&#123;2&#125;|2[0-4]\d|25[0-5]|[1-9]\d|\d)\.(1\d&#123;2&#125;|2[0-4]\d|25[0-5]|[1-9]\d|\d)$ 匹配ipv6如下 1^((?:[0-9A-Fa-f]&#123;1,4&#125;(?::[0-9A-Fa-f]&#123;1,4&#125;)*)?)::((?:[0-9A-Fa-f]&#123;1,4&#125;(?::[0-9A-Fa-f]&#123;1,4&#125;)*)?)$ python代码如下 12345678import redef check_ip(ipAddr): # reg_str 为上面的匹配字符串 compile_ip=re.compile(reg_str) if compile_ip.match(ipAddr): return True else: return False 注意:匹配ip地址注意将/后面的掩码去掉。ipv4掩码地址最大为32，ipv6最大为128 0x02 使用IPy库IPy是一个处理IP的第三方库。 使用pip安装如下 1pip install IPy python代码如下 1234567import IPydef is_ip(address): try: IPy.IP(address) # 可以判断ipv4和ipv6 return True except Exception as e: return False 0x03 总结使用正则表达式灵活高效，不用安装第三方库，缺点是正则表达式写起来很麻烦。本文权当记录了。 如果能够使用第三方库，建议使用IPy，方便快捷。]]></content>
      <categories>
        <category>编程基础</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>ip地址校验</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python 协程]]></title>
    <url>%2F2018%2F05%2F14%2Fpython-yield%E5%8D%8F%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[从语法上看，协程（coroutine）与生成器类似，都是定义体中包含yield关键字，协程中yield一般出现在表达式的右边，例如 value = yield None/val，可以生成值，也可以生成None。 0x01 协程生成器的基本行为下面来看一个简单的协程代码 123456789101112131415#! /usr/bin/python3def simple_coroutine(): print('start coroutine: ') x = yield print('receive x: ', x)if __name__ == '__main__': sc = simple_coroutine() # python2 使用sc.next() next(sc) #sc.send(None) try: sc.send('end and raise StopIteration Except') except StopIteration as e: print('end') 解释流程： 通过yield定义了一个协程生成器函数 创建一个协程生成器 调用next(…)启动协程，协程会运行到yield表达式处，然后暂停并切换到主函数的调用next的下一行。 调用send方法，把值传给yield变量，然后协程恢复执行，继续执行。 协程生成器函数结束时会抛出StopIteration异常。 执行结果如下 123start coroutine:receive x: end and raise StopIteration Exceptend 0x02 协程的四个状态 GEN_CREATED: 等待开始执行 GEN_RUNNING: 解释器正在执行 GEN_SUSPENED: 在yield表达式处暂停 GEN_CLOSED: 执行结束 上述例子的sc = simple_coroutine()语句为创建一个协程对象，此时协程处于GEN_CREATED状态。 第一次调用next()方法或者send(None)方法成为“预激”协程，此时协程处于GEN_RUNNING状态。 协程生成器函数执行到第一个yield语句处并暂停协程。暂停后协程处于GEN_SUSPENED状态。 协程执行结束后处于GEN_CLOSED状态。 0x03 协程异常处理和终止协程 generator.throw()方法会事处于暂停中的yield抛出一个执行的异常，如果生成器函数处理了该异常，则协程继续执行，否则会将该异常向上冒泡抛出。 使用generator.close()方法会使生成器在暂停的yield表达式处抛出GeneratorExit异常。如果生成器正常退出、已经关闭、或者产生一个GeneratorExit异常。如果生成器发送一个值，则并抛出RuntimeError异常并向上冒泡传递给调用方。 异常处理实例: 123456789101112131415161718192021222324#! /usr/bin/python3class DemoException(Exception): passdef handle_exception(): print('start handle exception') x = 0 while True: try: x = yield except DemoException: print('run demo exception') else: print('received x:', x) raise RuntimeError('this line should never run')handle = handle_exception()next(handle)handle.send(10)handle.throw(DemoException)handle.send(20)handle.throw(Exception)handle.close() 运行结果 12345678910start handle exceptionreceived x: 10run demo exceptionreceived x: 20Traceback (most recent call last): File "test3.py", line 23, in &lt;module&gt; handle.throw(Exception) File "test3.py", line 11, in handle_exception x = yieldException 可以看到生成器函数捕获了DemoException而没有捕获到Exception并向上冒泡抛出了该异常。 0x04 yield from用法注意：yield from是python3.3后加入的语法 基本用法 ​ 在生成器gen中使用yield from subgen()时，subgen子生成器会获取控制权，把生成的值传递给gen的调用方，即调用方可以直接控制subgen，同时gen会阻塞，等待subgen终止。 例如： 1234567891011121314# /usr/bin/python3def gen1(): for c in 'AB': yield c for i in range(1, 3): yield idef gen2(): yield from 'AB' yield from range(1, 3)print('gen1:', list(gen1()))print('gen2:', list(gen2())) 结果： 12gen1: ['A', 'B', 1, 2]gen2: ['A', 'B', 1, 2] 可以看到两个gen生成器得到的值相同。 高级用法 ​ 通过yield from将生成器生产的值委派给其他生成器。 再来看一个递归调用例子： 1234567891011121314# Example of flattening a nested sequence using subgeneratorsfrom collections import Iterabledef flatten(items, ignore_types=(str, bytes)): for x in items: if isinstance(x, Iterable) and not isinstance(x, ignore_types): yield from flatten(x) else: yield xitems = ['Dave', 'Paula', ['Thomas', 'Lewis']]for x in flatten(items): print(x) 运行结果 1234DavePaulaThomasLewis 可以看到flatten协程生成器的yield from调用了子flatten生成器函数。并将结果返回给了调用者。 下面这个例子是yield from的一个应用。 这段代码从一个字典中读取男生和女生的身高和体中，然后把数据传给之前定义的averager协程，最后生成一个报告。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566 #! -*- coding: utf-8 -*-from collections import namedtupleResult = namedtuple('Result', 'count average')# 子生成器# 这个例子和上边示例中的 averager 协程一样，只不过这里是作为字生成器使用def averager(): total = 0.0 count = 0 average = None while True: # main 函数发送数据到这里 term = yield if term is None: # 终止条件 break total += term count += 1 average = total/count return Result(count, average) # 返回的Result 会成为grouper函数中yield from表达式的值# 委派生成器def grouper(results, key): # 这个循环每次都会新建一个averager 实例，每个实例都是作为协程使用的生成器对象 while True: # grouper 发送的每个值都会经由yield from 处理，通过管道传给averager 实例。grouper会在yield from表达式处暂停，等待averager实例处理客户端发来的值。averager实例运行完毕后，返回的值绑定到results[key] 上。while 循环会不断创建averager实例，处理更多的值。 results[key] = yield from averager()# 调用方def main(data): results = &#123;&#125; for key, values in data.items(): # group 是调用grouper函数得到的生成器对象，传给grouper 函数的第一个参数是results，用于收集结果；第二个是某个键 group = grouper(results, key) next(group) for value in values: # 把各个value传给grouper 传入的值最终到达averager函数中； # grouper并不知道传入的是什么，同时grouper实例在yield from处暂停 group.send(value) # 把None传入groupper，传入的值最终到达averager函数中，导致当前实例终止。然后继续创建下一个实例。 # 如果没有group.send(None)，那么averager子生成器永远不会终止，委派生成器也永远不会在此激活，也就不会为result[key]赋值 group.send(None) report(results)# 输出报告def report(results): for key, result in sorted(results.items()): group, unit = key.split(';') print('&#123;:2&#125; &#123;:5&#125; averaging &#123;:.2f&#125;&#123;&#125;'.format(result.count, group, result.average, unit))data = &#123; 'girls;kg':[40, 41, 42, 43, 44, 54], 'girls;m': [1.5, 1.6, 1.8, 1.5, 1.45, 1.6], 'boys;kg':[50, 51, 62, 53, 54, 54], 'boys;m': [1.6, 1.8, 1.8, 1.7, 1.55, 1.6],&#125;if __name__ == '__main__': main(data) 结果如下 12346 boys averaging 54.00kg6 boys averaging 1.68m6 girls averaging 44.00kg6 girls averaging 1.58m 0x05 yield from意义 子生成器生产的值都直接传给委派给子生成器的调用方。 使用send()方法发送给委派生成器的值都直接传给子生成器。如果发送的值时None，那么会调用子生成器的next()方法。发送的值不为None,那么会调用子生成器的send()方法。如果调用的方法抛出了StopIteration异常，那么委派生成器恢复运行（关键点），其他任何异常都会向上冒泡传递给委派生成器。 生成器退出时，生成器或子生成器中的return expr表达式会触发StopIteration异常并向上冒泡抛出。 yield from表达式的值是子生成器终止时传给StopIteration异常的第一个参数,即return的值。 传入委派生成器的异常，初了GeneratorExit之外都传给了子生成器的throw()方法。如果调用throw()方法时抛出StopIteration异常，委派生成器恢复运行。StopIteration之外的异常会继续向上冒泡，传递给委派生成器。 如果把GeneratorExit异常传入委派生成器，或者在委派生成器上调用close()方法，如果有子生成器则也会在子生成器上调用close()方法。如果调用close()方法导致异常抛出，那么异常会向上冒泡，传递给委派生成器，否则委派生成器抛出GeneratorExit异常。 0x06 参考文档PEP 380 – Syntax for Delegating to a Subgenerator]]></content>
      <categories>
        <category>编程基础</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>协程</tag>
        <tag>yield</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python yield生成器]]></title>
    <url>%2F2018%2F05%2F13%2Fpython-yield%E7%94%9F%E6%88%90%E5%99%A8%2F</url>
    <content type="text"><![CDATA[yield基本用法是用来生成一个生成器 学习yield之前我们来了解下迭代器 0x01 迭代器python中支持迭代器协议就是实现一个支持__iter__()和next()方法的对象。__iter__()返回对象本身，next()返回迭代器容器的下一个元素。结尾时抛出一个StopIteration异常 下面来看一个迭代器生成例子 123456789101112131415161718192021#! /usr/bin/python2# coding=utf-8class MyIterators(): def __init__(self, num): self.number = num self.index = 0 def __iter__(self): return self def next(self): if self.index &lt; self.number: self.index += 1 return self.index else: raise StopIteration()my_iter = MyIterators(5)for i in my_iter: print i 运行结果如下 1234512345 0x02 生成器1. 生成器基本使用生成器函数用来返回一个迭代器。生成器是一个特殊的迭代器 使用生成器可以很方便的生成一个支持迭代器协议。生成器通过生成器函数产生。 生成器函数与普通函数一样通过def来定义，但是不用return返回值，由yield返回当前迭代的结果。yield返回结果后会挂起当前状态，由下一次迭代式继续执行。自动实现迭代协议。生成器函数中执行return操作不会返回一个值，而是抛出一个StopIteration异常终止迭代或者编程生成器的函数。 普通yield函数遇到return会抛出StopIteration异常，而yield from得到子生成器的StopIteration异常会恢复当前生成器，详情见yield协程用法的yield from章节。 注意：python2的next()用法为iter.next(),python3的用法为next(iter) 注意：yield不能嵌套，嵌套可以使用yield from。 生成器使用样例： 12345678910111213#! /usr/bin/python2# coding=utf-8def items_iterator(num): i = 0 while i &lt; num: yield i i += 1items = items_iterator(5)print itemsprint [i for i in items] 运行结果如下 12&lt;generator object items_iterator at 0x00000000028BBE58&gt;[0, 1, 2, 3, 4] 可以看到items时一个生成器对象。 当调用生成器函数时，函数只返回了一个生成器对象，并没有执行。 当第一次next()方法被调用时，生成器函数才开始执行，执行到yield处返回数据并停止执行。 继续调用next()方法的时候，生成器函数接着上次停止的地方继续执行。 2. 生成器的send()和close()方法 send(value)： 生成器的next()方法可以恢复生成器状态并继续执行，send()是另外一个恢复生成器状态。 send(None)和next()是等效的。 第一次调用生成器时请使用next()方法或者send(None)，否则会抛出异常。 send(value)的value作为一个参数会赋值给yield语句。 注意： 如果调用send方法时生成器没有处于挂起状态将抛出异常。 close()： 这个方法用于关于生成器，对关闭的生成器再次调用next或者send将抛出StopIteration异常。 下面例子可以观察send()方法发送参数 12345678910111213141516171819202122#! /usr/bin/python2# coding=utf-8def consumer(): r = 'here' while True: n1 = yield r if not n1: return print('[CONSUMER] Consuming %s...' % n1) r = '200 OK'+str(n1)def produce(c): aa = c.send(None) n = 0 while n &lt; 5: n = n + 1 print('[PRODUCER] Producing %s...' % n) r1 = c.send(n) print('[PRODUCER] Consumer return: %s' % r1) c.close()c = consumer()produce(c) 运行结果 12345678910[PRODUCER] Producing 1...[CONSUMER] Consuming 1...[PRODUCER] Consumer return: 200 OK1[PRODUCER] Producing 2...[CONSUMER] Consuming 2...[PRODUCER] Consumer return: 200 OK2[PRODUCER] Producing 3...[CONSUMER] Consuming 3...[PRODUCER] Consumer return: 200 OK3[PRODUCER] Producing 4... 可以看到每次迭代的n1值时send(n)发送的n，而不是’here’。 0x03 生成器的优点 对延迟操作良好提供支持 代码清晰简洁，更加pythonic 没有直接生成整个结果的list，而是返回一个迭代器，节约资源 用时运行，高效速度快]]></content>
      <categories>
        <category>编程基础</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>生成器</tag>
        <tag>迭代器</tag>
      </tags>
  </entry>
</search>
